{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/MultiModel/blob/master/Valid_94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1dxd2pySfCIDJYG7qMtuJre8ph068xc1X"
      ],
      "metadata": {
        "id": "BZSVygUtnh6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9c7a1a-d9e3-46e7-9736-caf4f1cc9142"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dxd2pySfCIDJYG7qMtuJre8ph068xc1X\n",
            "To: /content/fused_test.zip\n",
            "100% 2.12G/2.12G [00:35<00:00, 60.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1sYR9EgHkM0oiGRQVlFQCyHO8kMRJ4ibQ"
      ],
      "metadata": {
        "id": "ncvcZQTtn6bS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d850ba2b-0be3-4840-ba30-b586dc09fbd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sYR9EgHkM0oiGRQVlFQCyHO8kMRJ4ibQ\n",
            "To: /content/fused_test_label.txt\n",
            "\r  0% 0.00/777k [00:00<?, ?B/s]\r100% 777k/777k [00:00<00:00, 172MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1RciaCtImqRTT2-qq27GP6wKpIYfosAA3"
      ],
      "metadata": {
        "id": "mFD_5HDLnvTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cdc2d9-f15a-4dc0-e382-5d4cdb27e037"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RciaCtImqRTT2-qq27GP6wKpIYfosAA3\n",
            "To: /content/joint_test.zip\n",
            "100% 861M/861M [00:23<00:00, 36.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1giFuyrh33q_T1hfxcA0b-iBj_ix5w-sQ"
      ],
      "metadata": {
        "id": "3iPOl8sCnwlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9da7642-c16a-4013-9fc4-6d92a97c59f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1giFuyrh33q_T1hfxcA0b-iBj_ix5w-sQ\n",
            "To: /content/joint_test_label.txt\n",
            "\r  0% 0.00/528k [00:00<?, ?B/s]\r100% 528k/528k [00:00<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1UgMP8unIIcPtFAt4Htav9gIGmYxhoJGW"
      ],
      "metadata": {
        "id": "an8aFpGIqISG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232b3bc6-0c1c-4873-fc38-e73a56a4f6f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UgMP8unIIcPtFAt4Htav9gIGmYxhoJGW\n",
            "To: /content/15_model.pth\n",
            "100% 171M/171M [00:06<00:00, 27.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/joint_test.zip -d \"/content/joint/\""
      ],
      "metadata": {
        "id": "2KmQAo8bIPs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/fused_test.zip -d \"/content/fused/\""
      ],
      "metadata": {
        "id": "Lq4bSqN4IS2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HTftvdBXRhTJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "dPOyq7dZbgNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2ef59e-995b-4b8f-bcdf-223f6b92a92e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fused Validation"
      ],
      "metadata": {
        "id": "J1pXJJwyJOdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/fused/test\"\n",
        "labels_file = \"/content/fused_test_label.txt\"\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "\n",
        "        if not (filename.endswith(\"_1.png\") or filename.endswith(\"_2.png\")):\n",
        "            image_path = os.path.join(image_folder_add, filename)\n",
        "            image_file_paths.append(image_path)\n",
        "            genre_labels.append(labels)\n"
      ],
      "metadata": {
        "id": "1CwXZ1O2JP1X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQAHSUj7KJtn",
        "outputId": "182c3599-9d20-4476-fe71-392704117728"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7799"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100% Missing Modality"
      ],
      "metadata": {
        "id": "p189sy67JxGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# _3.png is for Encoded Image\n",
        "# _4.png is for Actual Image"
      ],
      "metadata": {
        "id": "YgODJ0JYLKCr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/joint/test\"\n",
        "labels_file = \"/content/joint_test_label.txt\"\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "\n",
        "        if filename.endswith(\"_4.png\"):\n",
        "            image_path = os.path.join(image_folder_add, filename)\n",
        "            image_file_paths.append(image_path)\n",
        "            genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "ynpL2klYJyAF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwSGQ4KyKHuh",
        "outputId": "ad124a5f-add3-4150-c49c-c45d441f4743"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7799"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partial Missing Modality"
      ],
      "metadata": {
        "id": "oJ2_570TOmQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Fused"
      ],
      "metadata": {
        "id": "ZmVu3IKXPGL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "fused_image_file_paths = []\n",
        "fused_genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/fused/test\"\n",
        "labels_file = \"/content/fused_test_label.txt\"\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "\n",
        "        if not (filename.endswith(\"_1.png\") or filename.endswith(\"_2.png\")):\n",
        "            image_path = os.path.join(image_folder_add, filename)\n",
        "            fused_image_file_paths.append(image_path)\n",
        "            fused_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "q6_JzJy3Oqkz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fused_image_file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sieP3GiPEl6",
        "outputId": "22ba982e-80a7-46ca-9fb9-1076bcba57cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7799"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KANHEn8iPVh8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Image Only"
      ],
      "metadata": {
        "id": "POjvuFIwPc_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# _3.png is for Encoded Image\n",
        "# _4.png is for Actual Image"
      ],
      "metadata": {
        "id": "ftkoQMJnd9ss"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "img_file_paths = []\n",
        "img_genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/joint/test\"\n",
        "labels_file = \"/content/joint_test_label.txt\"\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "\n",
        "        if filename.endswith(\"_4.png\"):\n",
        "            image_path = os.path.join(image_folder_add, filename)\n",
        "            img_file_paths.append(image_path)\n",
        "            img_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "cwtJhz39Pf4a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVMBX3XNPpGJ",
        "outputId": "84aca310-296c-4d74-f78f-bce0a9bfbacb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7799"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBuRK3ehPrfD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Selection"
      ],
      "metadata": {
        "id": "jrsK-0C-Sm1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = 0.5 # Fused Availability"
      ],
      "metadata": {
        "id": "wbE3eNhwSxqC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "total_samples = len(fused_image_file_paths)\n",
        "num_samples_from_fused = int(percentage * total_samples)\n",
        "num_samples_from_image = total_samples - num_samples_from_fused"
      ],
      "metadata": {
        "id": "CMe3-wp9Sq05"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total_samples\", total_samples)\n",
        "print(\"num_samples_from_fused\", num_samples_from_fused)\n",
        "print(\"num_samples_from_image\", num_samples_from_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igu7VBdDeW11",
        "outputId": "22d34aba-b0ac-46a6-802f-e39ea907ca7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_samples 7799\n",
            "num_samples_from_fused 3899\n",
            "num_samples_from_image 3900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_indices_fused = random.sample(range(total_samples), num_samples_from_fused)\n",
        "remaining_indices_image = [i for i in range(total_samples) if i not in random_indices_fused]\n",
        "\n",
        "\n",
        "image_file_paths = [fused_image_file_paths[i] for i in random_indices_fused] + [img_file_paths[i] for i in remaining_indices_image]\n",
        "genre_labels = [fused_genre_labels[i] for i in random_indices_fused] + [img_genre_labels[i] for i in remaining_indices_image]"
      ],
      "metadata": {
        "id": "lE26f9GOTRiE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_paths[7000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LhIGoUJkejq9",
        "outputId": "63b468e7-a37e-47b7-d134-44b4cb5e28e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/joint/test/3091242_4.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels[7000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqhgcI8oenBX",
        "outputId": "3ace10e0-24db-487b-b7af-b95828375159"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Comedy', 'Drama']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "1w1c6ddCKg7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "\n",
        "for labels in genre_labels:\n",
        "    for label in labels:\n",
        "        label_counts[label] += 1"
      ],
      "metadata": {
        "id": "TgQgz3cBKhW0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_count_list = [(label, count) for label, count in label_counts.items()]\n",
        "sorted_label_count_list = sorted(label_count_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for label, count in sorted_label_count_list:\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(\"Total Labels: \", len(label_count_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1NyQ4jVKiZI",
        "outputId": "4f90fd59-cae3-4d82-a3e6-50df3a24c5a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drama: 4142\n",
            "Comedy: 2611\n",
            "Romance: 1590\n",
            "Thriller: 1567\n",
            "Crime: 1163\n",
            "Action: 1044\n",
            "Horror: 825\n",
            "Adventure: 821\n",
            "Documentary: 629\n",
            "Mystery: 617\n",
            "Sci-Fi: 586\n",
            "Fantasy: 585\n",
            "Family: 518\n",
            "Biography: 411\n",
            "War: 401\n",
            "History: 345\n",
            "Music: 311\n",
            "Animation: 306\n",
            "Musical: 253\n",
            "Western: 210\n",
            "Sport: 191\n",
            "Short: 142\n",
            "Film-Noir: 102\n",
            "News: 19\n",
            "Adult: 1\n",
            "Total Labels:  25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_label_count = 20\n",
        "valid_labels = [label for label, count in label_counts.items() if count >= min_label_count]\n",
        "valid_labels = sorted(list(valid_labels))"
      ],
      "metadata": {
        "id": "jjIjX7twKsOr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels, len(valid_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJldcbI5Kvyc",
        "outputId": "239dc68a-99e4-4156-f8e2-c0cc489202fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Action',\n",
              "  'Adventure',\n",
              "  'Animation',\n",
              "  'Biography',\n",
              "  'Comedy',\n",
              "  'Crime',\n",
              "  'Documentary',\n",
              "  'Drama',\n",
              "  'Family',\n",
              "  'Fantasy',\n",
              "  'Film-Noir',\n",
              "  'History',\n",
              "  'Horror',\n",
              "  'Music',\n",
              "  'Musical',\n",
              "  'Mystery',\n",
              "  'Romance',\n",
              "  'Sci-Fi',\n",
              "  'Short',\n",
              "  'Sport',\n",
              "  'Thriller',\n",
              "  'War',\n",
              "  'Western'],\n",
              " 23)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MultiHot Encoding"
      ],
      "metadata": {
        "id": "aVh_shMHK0sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in valid_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "ndkQ-dBgK28s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqCyzIerK3d4",
        "outputId": "268ee308-4716-48fe-ef6a-f1428c13d21a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13t0HM8fK5iT",
        "outputId": "4e0663b1-c5c2-47f0-a61b-289a81623bef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Action', 'Crime', 'Drama', 'Thriller']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset and apply Transformation (ResNet)"
      ],
      "metadata": {
        "id": "wmwBygvfLZri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class CustomMultiLabelDataset(Dataset):\n",
        "    def __init__(self, image_file_paths, multi_encoded_labels, transform=None):\n",
        "        self.image_file_paths = image_file_paths\n",
        "        self.multi_encoded_labels = multi_encoded_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_file_paths[idx]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        labels = self.multi_encoded_labels[idx]\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, labels\n",
        "\n",
        "# Define data transformations (resize, normalize, etc.)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "jP04dLeHLaFn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset\n",
        "val_dataset = CustomMultiLabelDataset(image_file_paths, multi_hot_labels, transform=transform)\n",
        "print(len(val_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7LEJLN0Layt",
        "outputId": "c0ce6acb-a697-4bc0-b794-d7e0bd963ad6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model and Validation Loop (ResNet)"
      ],
      "metadata": {
        "id": "zNXm21P2lKQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import os\n",
        "\n",
        "save_dir = '/content/'\n",
        "load_path = os.path.join(save_dir, '15_model.pth')\n",
        "\n",
        "model = models.resnet101(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(valid_labels))\n",
        "model.load_state_dict(torch.load(load_path))\n",
        "\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "SsIJ_MdjL1la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "153lIoMpLpVz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Apply a threshold (e.g., 0.5) to convert logits to binary predictions\n",
        "        predictions.extend((outputs > 0.5).int().cpu().numpy())\n",
        "        true_labels.extend(labels.int().cpu().numpy())"
      ],
      "metadata": {
        "id": "V1C8zu8kMxS5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "recall = recall_score(true_labels, predictions, average='macro')\n",
        "f1 = f1_score(true_labels, predictions, average='macro')"
      ],
      "metadata": {
        "id": "Qo3yv027NCUm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzGxqHKwNNlk",
        "outputId": "9d9bdd2b-e002-4c65-acc4-f89437656f4c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0402615719964098\n",
            "Precision: 0.19790678895490435\n",
            "Recall: 0.1173766646024179\n",
            "F1-Score: 0.12222728613654656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_tSuJ3_NQDT",
        "outputId": "8fd714dd-2496-4875-dfc6-a3050f2a43a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.01      0.02      1044\n",
            "           1       0.26      0.07      0.11       821\n",
            "           2       0.42      0.06      0.10       306\n",
            "           3       0.06      0.34      0.09       411\n",
            "           4       0.55      0.35      0.43      2611\n",
            "           5       0.19      0.17      0.18      1163\n",
            "           6       0.15      0.08      0.10       629\n",
            "           7       0.57      0.70      0.63      4142\n",
            "           8       0.33      0.06      0.10       518\n",
            "           9       0.15      0.06      0.08       585\n",
            "          10       0.07      0.03      0.04       102\n",
            "          11       0.00      0.00      0.00       345\n",
            "          12       0.25      0.00      0.00       825\n",
            "          13       0.05      0.10      0.06       311\n",
            "          14       0.14      0.08      0.10       253\n",
            "          15       0.11      0.03      0.05       617\n",
            "          16       0.32      0.21      0.25      1590\n",
            "          17       0.10      0.04      0.06       586\n",
            "          18       0.09      0.11      0.10       142\n",
            "          19       0.02      0.01      0.01       191\n",
            "          20       0.41      0.13      0.20      1567\n",
            "          21       0.07      0.00      0.00       401\n",
            "          22       0.11      0.08      0.09       210\n",
            "\n",
            "   micro avg       0.34      0.26      0.30     19370\n",
            "   macro avg       0.20      0.12      0.12     19370\n",
            "weighted avg       0.33      0.26      0.26     19370\n",
            " samples avg       0.35      0.30      0.29     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset and Apply transformation (ViT)"
      ],
      "metadata": {
        "id": "OnDO1DCiiyIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets\n",
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import *\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LwYd4-YniyoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = {'image': image_file_paths, 'label': multi_hot_labels}\n",
        "ds_val = Dataset.from_dict(val_data)"
      ],
      "metadata": {
        "id": "PdyuGkvXi_Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "wS_rL2WhjBwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val['image'][0]"
      ],
      "metadata": {
        "id": "J-4CM-Q6jFGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = valid_labels\n",
        "labels"
      ],
      "metadata": {
        "id": "xHMrTOFWjFPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "CB0GazEujdFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTForImageClassification.from_pretrained(f\"/content/Model/Models-Train-18/checkpoint-81000\").to(device)\n",
        "image_processor = ViTImageProcessor.from_pretrained(f\"/content/Model/Models-Train-18/checkpoint-81000\")"
      ],
      "metadata": {
        "id": "IYmACS61jFWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as pil\n",
        "\n",
        "def transform(examples):\n",
        "  inputs = image_processor([pil.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs[\"labels\"] = examples[\"label\"]\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "iVpwGu5UjFcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = ds_val.with_transform(transform)"
      ],
      "metadata": {
        "id": "X5-TuOYFjmPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "id": "aDYXLb8EjpnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = val_dataset[0]"
      ],
      "metadata": {
        "id": "h_I6n33djr79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "ozGHp_XpjuTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in val_dataset:\n",
        "  print(item['pixel_values'].shape)\n",
        "  print(item[\"labels\"])\n",
        "  break"
      ],
      "metadata": {
        "id": "kSp1wDWdju1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
        "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "  }"
      ],
      "metadata": {
        "id": "kumR8n8sj0F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "valid_dataset_loader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Gwq7UBrJj5nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "predictions, labels = [], []\n",
        "valid_loss = 0\n",
        "\n",
        "for batch in valid_dataset_loader:\n",
        "    pixel_values = batch[\"pixel_values\"].to(device)\n",
        "    label_ids = batch[\"labels\"].to(device).float()\n",
        "\n",
        "    outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
        "\n",
        "    loss = outputs.loss\n",
        "    valid_loss += loss.item()\n",
        "\n",
        "    logits = outputs.logits.detach().cpu()\n",
        "\n",
        "    # predictions.extend(logits.argmax(dim=-1).tolist())\n",
        "    # labels.extend(label_ids.tolist())\n",
        "    predictions.extend((logits > 0.5).int().cpu().numpy())\n",
        "    labels.extend(label_ids.int().cpu().numpy())"
      ],
      "metadata": {
        "id": "jF-KBkj7kAWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(labels, predictions)\n",
        "precision = precision_score(labels, predictions, average='macro')\n",
        "recall = recall_score(labels, predictions, average='macro')\n",
        "f1 = f1_score(labels, predictions, average='macro')"
      ],
      "metadata": {
        "id": "Us9pLc9pkBFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "LnW_vy4XkI9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(labels, predictions))"
      ],
      "metadata": {
        "id": "tBJ2m3ikkKpg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "J1pXJJwyJOdp",
        "p189sy67JxGD",
        "oJ2_570TOmQZ",
        "1w1c6ddCKg7z",
        "wmwBygvfLZri"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}