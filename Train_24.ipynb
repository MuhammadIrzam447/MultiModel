{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9f2eb27983c4d0ead78243858a603e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02ef30fbecf6497bbc265bc8631df591",
              "IPY_MODEL_23e0bdbd278c45a58442cfb46134fd38",
              "IPY_MODEL_0826a7d4a1aa4c48ad837f0b52c7b465"
            ],
            "layout": "IPY_MODEL_faeaab8f12994276b6c10c284c677177"
          }
        },
        "02ef30fbecf6497bbc265bc8631df591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1f44a4b91d48c286dac01894804c39",
            "placeholder": "​",
            "style": "IPY_MODEL_fcc2d13b50164f7ca63b9af229b5c231",
            "value": "Filter: 100%"
          }
        },
        "23e0bdbd278c45a58442cfb46134fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b45938a48547469abfbc0491503f4c",
            "max": 23397,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_506d63b4bdc14bbd943b852faa454150",
            "value": 23397
          }
        },
        "0826a7d4a1aa4c48ad837f0b52c7b465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c75834ef8b2146f5be6c0df701f0de0a",
            "placeholder": "​",
            "style": "IPY_MODEL_1130d15832d54b4c9d4fe913b4ded420",
            "value": " 23397/23397 [00:00&lt;00:00, 35358.62 examples/s]"
          }
        },
        "faeaab8f12994276b6c10c284c677177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1f44a4b91d48c286dac01894804c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc2d13b50164f7ca63b9af229b5c231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b45938a48547469abfbc0491503f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506d63b4bdc14bbd943b852faa454150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c75834ef8b2146f5be6c0df701f0de0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1130d15832d54b4c9d4fe913b4ded420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/MultiModel/blob/master/Train_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmF1zNcPTGga"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1jX_5n1kiiLI7Yl72ljkBMSiVgSlg254w"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1D7PMsXUxkmqskMpfy5LzFfPyJH0Ngf3q"
      ],
      "metadata": {
        "id": "KKm0C_4oTUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1RciaCtImqRTT2-qq27GP6wKpIYfosAA3"
      ],
      "metadata": {
        "id": "Hou-hwbv0W6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1giFuyrh33q_T1hfxcA0b-iBj_ix5w-sQ"
      ],
      "metadata": {
        "id": "WQeDAAyZ0WLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip joint_test.zip"
      ],
      "metadata": {
        "id": "Q--gX0z1yYPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip joint_train.zip"
      ],
      "metadata": {
        "id": "gc3k8cZ10bwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "KCfJth3zqdZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Dataset"
      ],
      "metadata": {
        "id": "27JUbagnvJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_image_file_paths = []\n",
        "train_genre_labels = []\n",
        "\n",
        "train_image_folder_add = \"/content/Dataset(s)/mm-imdb/fused/train\"\n",
        "train_labels_file = \"/content/Dataset(s)/mm-imdb/fused/train_label.txt\"\n",
        "\n",
        "with open(train_labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(train_image_folder_add, filename)\n",
        "        train_image_file_paths.append(image_path)\n",
        "        train_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "SGASG2u5vIGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_image_file_paths)"
      ],
      "metadata": {
        "id": "aVDEkUt8SEY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e225566-2c71-4b76-dbf8-b9774c7fb00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46656"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "\n",
        "for labels in train_genre_labels:\n",
        "    for label in labels:\n",
        "        label_counts[label] += 1"
      ],
      "metadata": {
        "id": "YF6Tgrj3F6Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts"
      ],
      "metadata": {
        "id": "fIpNexHFH5-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e393a20f-863f-4049-bea6-07d521efc690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'Crime': 6879,\n",
              "             'Drama': 25272,\n",
              "             'Thriller': 9339,\n",
              "             'Action': 6465,\n",
              "             'Comedy': 15324,\n",
              "             'Romance': 9678,\n",
              "             'Documentary': 3702,\n",
              "             'Short': 843,\n",
              "             'Mystery': 3693,\n",
              "             'History': 2040,\n",
              "             'Family': 2934,\n",
              "             'Adventure': 4833,\n",
              "             'Fantasy': 3486,\n",
              "             'Sci-Fi': 3636,\n",
              "             'Western': 1269,\n",
              "             'Horror': 4809,\n",
              "             'Sport': 1137,\n",
              "             'War': 2418,\n",
              "             'Music': 1902,\n",
              "             'Musical': 1509,\n",
              "             'Animation': 1758,\n",
              "             'Biography': 2364,\n",
              "             'Film-Noir': 606,\n",
              "             'News': 117,\n",
              "             'Talk-Show': 6,\n",
              "             'Reality-TV': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the defaultdict into a list of tuples\n",
        "label_count_list = [(label, count) for label, count in label_counts.items()]\n",
        "\n",
        "# Sort the list of tuples based on counts in descending order\n",
        "sorted_label_count_list = sorted(label_count_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the sorted list\n",
        "for label, count in sorted_label_count_list:\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(\"Total Labels: \", len(label_count_list))"
      ],
      "metadata": {
        "id": "rzB9k8aeF6cH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddeee49-8649-44b0-c9d6-09e517f3d1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drama: 25272\n",
            "Comedy: 15324\n",
            "Romance: 9678\n",
            "Thriller: 9339\n",
            "Crime: 6879\n",
            "Action: 6465\n",
            "Adventure: 4833\n",
            "Horror: 4809\n",
            "Documentary: 3702\n",
            "Mystery: 3693\n",
            "Sci-Fi: 3636\n",
            "Fantasy: 3486\n",
            "Family: 2934\n",
            "War: 2418\n",
            "Biography: 2364\n",
            "History: 2040\n",
            "Music: 1902\n",
            "Animation: 1758\n",
            "Musical: 1509\n",
            "Western: 1269\n",
            "Sport: 1137\n",
            "Short: 843\n",
            "Film-Noir: 606\n",
            "News: 117\n",
            "Talk-Show: 6\n",
            "Reality-TV: 3\n",
            "Total Labels:  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_label_count = 400\n",
        "valid_labels = [label for label, count in label_counts.items() if count >= min_label_count]\n",
        "valid_labels = sorted(list(valid_labels))"
      ],
      "metadata": {
        "id": "kEakjRS5F_bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels, len(valid_labels)"
      ],
      "metadata": {
        "id": "elYCUFKfGCjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6591b28-a93b-4800-9d68-355cf7a79bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Action',\n",
              "  'Adventure',\n",
              "  'Animation',\n",
              "  'Biography',\n",
              "  'Comedy',\n",
              "  'Crime',\n",
              "  'Documentary',\n",
              "  'Drama',\n",
              "  'Family',\n",
              "  'Fantasy',\n",
              "  'Film-Noir',\n",
              "  'History',\n",
              "  'Horror',\n",
              "  'Music',\n",
              "  'Musical',\n",
              "  'Mystery',\n",
              "  'Romance',\n",
              "  'Sci-Fi',\n",
              "  'Short',\n",
              "  'Sport',\n",
              "  'Thriller',\n",
              "  'War',\n",
              "  'Western'],\n",
              " 23)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(valid_labels)\n",
        "label2id = {label: str(i) for i, label in enumerate(valid_labels)}\n",
        "id2label = {str(i): label for i, label in enumerate(valid_labels)}"
      ],
      "metadata": {
        "id": "3erAiX-pv1PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "IYSgaj2cwKDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9da06a-d179-4bff-ba84-d69ae19f1a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'Action',\n",
              " '1': 'Adventure',\n",
              " '2': 'Animation',\n",
              " '3': 'Biography',\n",
              " '4': 'Comedy',\n",
              " '5': 'Crime',\n",
              " '6': 'Documentary',\n",
              " '7': 'Drama',\n",
              " '8': 'Family',\n",
              " '9': 'Fantasy',\n",
              " '10': 'Film-Noir',\n",
              " '11': 'History',\n",
              " '12': 'Horror',\n",
              " '13': 'Music',\n",
              " '14': 'Musical',\n",
              " '15': 'Mystery',\n",
              " '16': 'Romance',\n",
              " '17': 'Sci-Fi',\n",
              " '18': 'Short',\n",
              " '19': 'Sport',\n",
              " '20': 'Thriller',\n",
              " '21': 'War',\n",
              " '22': 'Western'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels"
      ],
      "metadata": {
        "id": "TX4BGI9_wNfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c0ee2c-7ca6-4722-dd03-ba74c2625965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_labels = []\n",
        "\n",
        "for labels in train_genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in valid_labels]\n",
        "    train_multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "fkFtTj2FvWpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_labels[0]"
      ],
      "metadata": {
        "id": "qEDvj2BJIKsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e115d2-5346-4c0b-9a6c-24842c71c083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_genre_labels[0]"
      ],
      "metadata": {
        "id": "sRFZ9Z9rIOSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6abf770-2175-4252-f952-4e8d469e2206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Crime', 'Drama', 'Thriller']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Dataset"
      ],
      "metadata": {
        "id": "5PZTetjHFJv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"/content/Dataset(s)/mm-imdb/fused/test\"\n",
        "labels_file = '/content/Dataset(s)/mm-imdb/fused/test_label.txt'\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        image_file_paths.append(image_path)\n",
        "        genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "AA5mDiCVFMDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_file_paths)"
      ],
      "metadata": {
        "id": "ZL0rp0CzIbzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e823ae86-af84-46b5-d39d-e28b92deb7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23397"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_paths[0:10]"
      ],
      "metadata": {
        "id": "8vxqITtzTdSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbe4e2a-162c-4c4c-ba5a-6eda37ca8756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset(s)/mm-imdb/fused/test/0078718.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0078718_1.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0078718_2.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0089003.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0089003_1.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0089003_2.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0098136.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0098136_1.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0098136_2.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0057693.png']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from collections import defaultdict\n",
        "\n",
        "# label_counts = defaultdict(int)\n",
        "\n",
        "# for labels in genre_labels:\n",
        "#     for label in labels:\n",
        "#         label_counts[label] += 1"
      ],
      "metadata": {
        "id": "0JN9GGSfGcR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_counts"
      ],
      "metadata": {
        "id": "uE1LswS-Gh5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_count_list = [(label, count) for label, count in label_counts.items()]\n",
        "# sorted_label_count_list = sorted(label_count_list, key=lambda x: x[1], reverse=True)\n",
        "# for label, count in sorted_label_count_list:\n",
        "#     print(f\"{label}: {count}\")\n",
        "# print(\"Total Labels: \", len(label_count_list))"
      ],
      "metadata": {
        "id": "jaUebffvJFvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in valid_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "11mF79hnFNBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Datasets"
      ],
      "metadata": {
        "id": "wPeiQ6yyvNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets\n",
        "from datasets import Dataset\n",
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import *\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "G9Nsa_BDrGNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {'image': train_image_file_paths, 'label': train_multi_hot_labels}\n",
        "ds_train = Dataset.from_dict(train_data)\n",
        "\n",
        "val_data = {'image': image_file_paths, 'label': multi_hot_labels}\n",
        "ds_val = Dataset.from_dict(val_data)"
      ],
      "metadata": {
        "id": "a4mLnUT7qd5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train"
      ],
      "metadata": {
        "id": "3SjM0TVurJGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8858b168-1924-478b-a16b-c60c71243f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 46656\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "O8mdfwrqwykE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5ff66f-e8ab-49d6-a05d-4bec936498f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 23397\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def filter_function(example):\n",
        "    filename = example[\"image\"]\n",
        "    return not (filename.endswith(\"_1.png\") or filename.endswith(\"_2.png\"))"
      ],
      "metadata": {
        "id": "j8kynSG3dJ2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = ds_val.filter(filter_function)"
      ],
      "metadata": {
        "id": "qhNKgZdzdMWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a9f2eb27983c4d0ead78243858a603e9",
            "02ef30fbecf6497bbc265bc8631df591",
            "23e0bdbd278c45a58442cfb46134fd38",
            "0826a7d4a1aa4c48ad837f0b52c7b465",
            "faeaab8f12994276b6c10c284c677177",
            "3c1f44a4b91d48c286dac01894804c39",
            "fcc2d13b50164f7ca63b9af229b5c231",
            "08b45938a48547469abfbc0491503f4c",
            "506d63b4bdc14bbd943b852faa454150",
            "c75834ef8b2146f5be6c0df701f0de0a",
            "1130d15832d54b4c9d4fe913b4ded420"
          ]
        },
        "outputId": "30e9f056-ae3b-47d4-a97b-dc3781187e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/23397 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9f2eb27983c4d0ead78243858a603e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "hrUWaxleepOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026100d7-4948-4c27-a791-c06dac54523e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 7799\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train['image'][0], ds_val['image'][0], ds_train['image'][1], ds_val['image'][1]"
      ],
      "metadata": {
        "id": "R5kP5p4_r008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866bef69-4123-42bd-8826-fac15bc9758f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/Dataset(s)/mm-imdb/fused/train/0106714.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0078718.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/train/0106714_1.png',\n",
              " '/content/Dataset(s)/mm-imdb/fused/test/0089003.png')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = ds.features[\"label\"]\n",
        "labels = valid_labels\n",
        "labels"
      ],
      "metadata": {
        "id": "iZAsVZXkrMHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d06cfd0-9fb5-42b6-c8c9-540799dd663e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Action',\n",
              " 'Adventure',\n",
              " 'Animation',\n",
              " 'Biography',\n",
              " 'Comedy',\n",
              " 'Crime',\n",
              " 'Documentary',\n",
              " 'Drama',\n",
              " 'Family',\n",
              " 'Fantasy',\n",
              " 'Film-Noir',\n",
              " 'History',\n",
              " 'Horror',\n",
              " 'Music',\n",
              " 'Musical',\n",
              " 'Mystery',\n",
              " 'Romance',\n",
              " 'Sci-Fi',\n",
              " 'Short',\n",
              " 'Sport',\n",
              " 'Thriller',\n",
              " 'War',\n",
              " 'Western']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Model"
      ],
      "metadata": {
        "id": "ac-q2lZhuxBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "T1YZ7kVesVM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a40add-b88e-4eea-df4b-1f2cf5034430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "qXK14nDosWFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as pil\n",
        "\n",
        "def transform(examples):\n",
        "  # inputs = image_processor([Image.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs = image_processor([pil.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs[\"labels\"] = examples[\"label\"]\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "bpeUOPS2v_qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ds_train.with_transform(transform)\n",
        "val_dataset = ds_val.with_transform(transform)"
      ],
      "metadata": {
        "id": "DZUEGqDlwEZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "WgMgw6nswEo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732b29c2-1192-456f-baa1-4d2ac38ed284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 46656\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "id": "2cC5DlJQxNzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d11daed-fd45-49b3-afe7-a5ede37800b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 7799\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[0]\n",
        "# img = sample[\"pixel_values\"]\n",
        "# filename = os.path.basename(img.filename)\n",
        "# print(f\"File Name: {filename}\")"
      ],
      "metadata": {
        "id": "Yu09sABJUxNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "u9Yfq17FYtIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad20af2-1f0c-46f1-b580-e11a2bf6ebda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]],\n",
              " \n",
              "         [[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]],\n",
              " \n",
              "         [[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]]]),\n",
              " 'labels': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataset:\n",
        "  print(item['pixel_values'].shape)\n",
        "  print(item[\"labels\"])\n",
        "  break"
      ],
      "metadata": {
        "id": "GMi1dn5qzHn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf0636f-db13-49e3-8a67-59fda2bcd752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
        "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "  }"
      ],
      "metadata": {
        "id": "6J-LWUv_wE48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attach Final Layer to Model"
      ],
      "metadata": {
        "id": "nNN2igTOxdjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ViT model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels= len(valid_labels),\n",
        "    label2id = {label: str(i) for i, label in enumerate(valid_labels)},\n",
        "    id2label = {str(i): label for i, label in enumerate(valid_labels)},\n",
        "    problem_type = \"multi_label_classification\",\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ge9TkjxDvU7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17dcd219-737d-4a68-d286-877b03ca4df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/3f49326eb077187dfe1c2a2bb15fbd74e6ab91e3/config.json\n",
            "Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
            "  \"architectures\": [\n",
            "    \"ViTForImageClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"Action\",\n",
            "    \"1\": \"Adventure\",\n",
            "    \"10\": \"Film-Noir\",\n",
            "    \"11\": \"History\",\n",
            "    \"12\": \"Horror\",\n",
            "    \"13\": \"Music\",\n",
            "    \"14\": \"Musical\",\n",
            "    \"15\": \"Mystery\",\n",
            "    \"16\": \"Romance\",\n",
            "    \"17\": \"Sci-Fi\",\n",
            "    \"18\": \"Short\",\n",
            "    \"19\": \"Sport\",\n",
            "    \"2\": \"Animation\",\n",
            "    \"20\": \"Thriller\",\n",
            "    \"21\": \"War\",\n",
            "    \"22\": \"Western\",\n",
            "    \"3\": \"Biography\",\n",
            "    \"4\": \"Comedy\",\n",
            "    \"5\": \"Crime\",\n",
            "    \"6\": \"Documentary\",\n",
            "    \"7\": \"Drama\",\n",
            "    \"8\": \"Family\",\n",
            "    \"9\": \"Fantasy\"\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"Action\": \"0\",\n",
            "    \"Adventure\": \"1\",\n",
            "    \"Animation\": \"2\",\n",
            "    \"Biography\": \"3\",\n",
            "    \"Comedy\": \"4\",\n",
            "    \"Crime\": \"5\",\n",
            "    \"Documentary\": \"6\",\n",
            "    \"Drama\": \"7\",\n",
            "    \"Family\": \"8\",\n",
            "    \"Fantasy\": \"9\",\n",
            "    \"Film-Noir\": \"10\",\n",
            "    \"History\": \"11\",\n",
            "    \"Horror\": \"12\",\n",
            "    \"Music\": \"13\",\n",
            "    \"Musical\": \"14\",\n",
            "    \"Mystery\": \"15\",\n",
            "    \"Romance\": \"16\",\n",
            "    \"Sci-Fi\": \"17\",\n",
            "    \"Short\": \"18\",\n",
            "    \"Sport\": \"19\",\n",
            "    \"Thriller\": \"20\",\n",
            "    \"War\": \"21\",\n",
            "    \"Western\": \"22\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"problem_type\": \"multi_label_classification\",\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.32.1\"\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/3f49326eb077187dfe1c2a2bb15fbd74e6ab91e3/model.safetensors\n",
            "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
            "\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([23]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([23, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Hyperparameters"
      ],
      "metadata": {
        "id": "mNzrUMBDvAps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "QSaA0l0kvfD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset_loader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "H9a305Thv487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "pDTtvcPav0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"/content/Untitled Folder\"\n",
        "summary_writer = SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "0u-AcYYPBCIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qxzkS9aDBEP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps = num_epochs * len(train_dataset_loader)\n",
        "n_valid_steps = len(valid_dataset_loader)\n",
        "current_step = 0"
      ],
      "metadata": {
        "id": "dbdQh7a9BMQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps , n_valid_steps"
      ],
      "metadata": {
        "id": "0zupZcnNxti1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba931e-838f-4c88-c554-9c64713db982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43740, 244)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging, eval & save steps\n",
        "save_steps = 3000"
      ],
      "metadata": {
        "id": "aS9zwwA3BXUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#   accuracy_score = accuracy.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
        "#   f1_score = f1.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids, average=\"macro\")\n",
        "#   return {**accuracy_score, **f1_score}"
      ],
      "metadata": {
        "id": "f7H1EL2TBVPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # progress_bar = tqdm(range(current_step, n_train_steps), \"Training\", dynamic_ncols=True, ncols=80)\n",
        "\n",
        "    for batch in train_dataset_loader:\n",
        "      if (current_step+1) % save_steps == 0:\n",
        "        print()\n",
        "        print(f\"Validation at step {current_step}...\")\n",
        "        print()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        predictions, labels = [], []\n",
        "        valid_loss = 0\n",
        "\n",
        "        for batch in valid_dataset_loader:\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            label_ids = batch[\"labels\"].to(device).float()\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits.detach().cpu()\n",
        "\n",
        "            # predictions.extend((logits > 0.5).int().cpu().numpy())\n",
        "            predictions.extend(F.sigmoid(logits).cpu().numpy())\n",
        "            labels.extend(label_ids.int().cpu().numpy())\n",
        "\n",
        "        # eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
        "        # metrics = compute_metrics(eval_prediction)\n",
        "        print()\n",
        "        print(f\"Epoch: {epoch}, Step: {current_step}, Train Loss: {train_loss / save_steps:.4f}, \" +\n",
        "              f\"Valid Loss: {valid_loss / n_valid_steps:.4f}\") # , Accuracy: {metrics['accuracy']}, \" + f\"F1 Score: {metrics['f1']}\")\n",
        "        print()\n",
        "\n",
        "        # summary_writer.add_scalar(\"valid_loss\", valid_loss / n_valid_steps, global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"accuracy\", metrics[\"accuracy\"], global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"f1\", metrics[\"f1\"], global_step=current_step)\n",
        "\n",
        "        model.save_pretrained(f\"/content/Model/Models-Train-24/checkpoint-{current_step}\")\n",
        "        image_processor.save_pretrained(f\"/content/Model/Models-Train-24/checkpoint-{current_step}\")\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        threshold = 0.5\n",
        "        predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        precision = precision_score(labels, predictions, average='macro')\n",
        "        recall = recall_score(labels, predictions, average='macro')\n",
        "        f1 = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-Score: {f1}\")\n",
        "        print(classification_report(labels, predictions))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, valid_loss = 0, 0\n",
        "\n",
        "      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device).float()\n",
        "\n",
        "      outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_v = loss.item()\n",
        "      train_loss += loss_v\n",
        "\n",
        "      current_step += 1\n",
        "      # progress_bar.update(1)\n",
        "      summary_writer.add_scalar(\"train_loss\", loss_v, global_step=current_step)"
      ],
      "metadata": {
        "id": "PXHxhHIqCGR7",
        "outputId": "39ebac1d-cf49-4ee4-e1c9-2225426cffce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 2999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-2999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Step: 2999, Train Loss: 0.0056, Valid Loss: 0.2261\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-2999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-2999/preprocessor_config.json\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1379664059494807\n",
            "Precision: 0.4930785540004638\n",
            "Recall: 0.22696106866709395\n",
            "F1-Score: 0.276543350444587\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.46      0.50      1044\n",
            "           1       0.52      0.35      0.42       821\n",
            "           2       0.81      0.44      0.57       306\n",
            "           3       0.00      0.00      0.00       411\n",
            "           4       0.71      0.51      0.59      2611\n",
            "           5       0.61      0.27      0.37      1163\n",
            "           6       0.73      0.44      0.55       629\n",
            "           7       0.72      0.65      0.69      4142\n",
            "           8       0.71      0.32      0.45       518\n",
            "           9       0.54      0.15      0.23       585\n",
            "          10       0.00      0.00      0.00       102\n",
            "          11       0.30      0.01      0.02       345\n",
            "          12       0.66      0.48      0.56       825\n",
            "          13       0.00      0.00      0.00       311\n",
            "          14       0.50      0.01      0.02       253\n",
            "          15       0.57      0.01      0.03       617\n",
            "          16       0.64      0.13      0.21      1590\n",
            "          17       0.52      0.39      0.45       586\n",
            "          18       0.00      0.00      0.00       142\n",
            "          19       0.00      0.00      0.00       191\n",
            "          20       0.58      0.48      0.53      1567\n",
            "          21       0.69      0.11      0.19       401\n",
            "          22       1.00      0.00      0.01       210\n",
            "\n",
            "   micro avg       0.66      0.38      0.48     19370\n",
            "   macro avg       0.49      0.23      0.28     19370\n",
            "weighted avg       0.61      0.38      0.44     19370\n",
            " samples avg       0.61      0.43      0.47     19370\n",
            "\n",
            "\n",
            "Validation at step 5999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-5999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4, Step: 5999, Train Loss: 0.0079, Valid Loss: 0.2240\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-5999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-5999/preprocessor_config.json\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14796768816514938\n",
            "Precision: 0.5662976098598883\n",
            "Recall: 0.25440678151936574\n",
            "F1-Score: 0.3183008782837863\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47      1044\n",
            "           1       0.59      0.28      0.38       821\n",
            "           2       0.74      0.46      0.57       306\n",
            "           3       0.43      0.01      0.03       411\n",
            "           4       0.67      0.54      0.60      2611\n",
            "           5       0.59      0.35      0.44      1163\n",
            "           6       0.76      0.53      0.63       629\n",
            "           7       0.69      0.78      0.73      4142\n",
            "           8       0.72      0.36      0.48       518\n",
            "           9       0.54      0.17      0.26       585\n",
            "          10       0.18      0.02      0.04       102\n",
            "          11       0.51      0.06      0.10       345\n",
            "          12       0.68      0.48      0.56       825\n",
            "          13       0.29      0.01      0.01       311\n",
            "          14       0.42      0.06      0.10       253\n",
            "          15       0.51      0.07      0.13       617\n",
            "          16       0.52      0.26      0.35      1590\n",
            "          17       0.73      0.26      0.38       586\n",
            "          18       0.50      0.01      0.01       142\n",
            "          19       0.44      0.02      0.04       191\n",
            "          20       0.62      0.39      0.48      1567\n",
            "          21       0.61      0.24      0.35       401\n",
            "          22       0.66      0.11      0.19       210\n",
            "\n",
            "   micro avg       0.66      0.42      0.52     19370\n",
            "   macro avg       0.57      0.25      0.32     19370\n",
            "weighted avg       0.62      0.42      0.48     19370\n",
            " samples avg       0.64      0.48      0.51     19370\n",
            "\n",
            "\n",
            "Validation at step 8999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-8999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6, Step: 8999, Train Loss: 0.0073, Valid Loss: 0.2504\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-8999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-8999/preprocessor_config.json\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.13488908834465957\n",
            "Precision: 0.5446321604105495\n",
            "Recall: 0.274337739981535\n",
            "F1-Score: 0.33363741251356654\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.46      0.50      1044\n",
            "           1       0.54      0.30      0.39       821\n",
            "           2       0.78      0.47      0.59       306\n",
            "           3       0.41      0.02      0.04       411\n",
            "           4       0.63      0.57      0.59      2611\n",
            "           5       0.52      0.39      0.44      1163\n",
            "           6       0.72      0.47      0.57       629\n",
            "           7       0.70      0.73      0.71      4142\n",
            "           8       0.71      0.37      0.49       518\n",
            "           9       0.53      0.16      0.25       585\n",
            "          10       0.13      0.02      0.03       102\n",
            "          11       0.48      0.07      0.13       345\n",
            "          12       0.69      0.47      0.56       825\n",
            "          13       0.45      0.03      0.05       311\n",
            "          14       0.36      0.03      0.06       253\n",
            "          15       0.45      0.13      0.21       617\n",
            "          16       0.48      0.28      0.36      1590\n",
            "          17       0.56      0.36      0.44       586\n",
            "          18       0.60      0.02      0.04       142\n",
            "          19       0.54      0.07      0.12       191\n",
            "          20       0.55      0.46      0.50      1567\n",
            "          21       0.59      0.26      0.36       401\n",
            "          22       0.58      0.16      0.25       210\n",
            "\n",
            "   micro avg       0.62      0.44      0.51     19370\n",
            "   macro avg       0.54      0.27      0.33     19370\n",
            "weighted avg       0.59      0.44      0.48     19370\n",
            " samples avg       0.61      0.49      0.50     19370\n",
            "\n",
            "\n",
            "Validation at step 11999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-11999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8, Step: 11999, Train Loss: 0.0050, Valid Loss: 0.2961\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-11999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-11999/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.12322092575971279\n",
            "Precision: 0.5173863271021092\n",
            "Recall: 0.2891678321557566\n",
            "F1-Score: 0.3486069081662056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.44      0.50      1044\n",
            "           1       0.53      0.29      0.38       821\n",
            "           2       0.77      0.47      0.59       306\n",
            "           3       0.26      0.06      0.10       411\n",
            "           4       0.62      0.56      0.59      2611\n",
            "           5       0.53      0.38      0.44      1163\n",
            "           6       0.68      0.51      0.58       629\n",
            "           7       0.69      0.74      0.71      4142\n",
            "           8       0.74      0.34      0.47       518\n",
            "           9       0.47      0.17      0.25       585\n",
            "          10       0.12      0.02      0.03       102\n",
            "          11       0.37      0.10      0.15       345\n",
            "          12       0.65      0.48      0.55       825\n",
            "          13       0.34      0.07      0.12       311\n",
            "          14       0.36      0.06      0.10       253\n",
            "          15       0.38      0.20      0.26       617\n",
            "          16       0.44      0.28      0.34      1590\n",
            "          17       0.52      0.41      0.46       586\n",
            "          18       0.64      0.05      0.09       142\n",
            "          19       0.55      0.09      0.16       191\n",
            "          20       0.53      0.47      0.50      1567\n",
            "          21       0.64      0.27      0.38       401\n",
            "          22       0.54      0.19      0.28       210\n",
            "\n",
            "   micro avg       0.60      0.44      0.51     19370\n",
            "   macro avg       0.52      0.29      0.35     19370\n",
            "weighted avg       0.57      0.44      0.48     19370\n",
            " samples avg       0.60      0.49      0.50     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 14999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-14999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 10, Step: 14999, Train Loss: 0.0029, Valid Loss: 0.3525\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-14999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-14999/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.12347736889344788\n",
            "Precision: 0.5135139050004095\n",
            "Recall: 0.28192563919347075\n",
            "F1-Score: 0.3455309362655827\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.41      0.48      1044\n",
            "           1       0.51      0.32      0.39       821\n",
            "           2       0.73      0.51      0.60       306\n",
            "           3       0.27      0.05      0.09       411\n",
            "           4       0.61      0.56      0.59      2611\n",
            "           5       0.57      0.32      0.41      1163\n",
            "           6       0.70      0.50      0.58       629\n",
            "           7       0.68      0.73      0.71      4142\n",
            "           8       0.66      0.37      0.48       518\n",
            "           9       0.48      0.19      0.28       585\n",
            "          10       0.08      0.01      0.02       102\n",
            "          11       0.33      0.08      0.13       345\n",
            "          12       0.68      0.44      0.54       825\n",
            "          13       0.32      0.06      0.11       311\n",
            "          14       0.39      0.06      0.11       253\n",
            "          15       0.41      0.14      0.21       617\n",
            "          16       0.46      0.27      0.34      1590\n",
            "          17       0.56      0.37      0.45       586\n",
            "          18       0.58      0.08      0.14       142\n",
            "          19       0.48      0.12      0.19       191\n",
            "          20       0.54      0.43      0.48      1567\n",
            "          21       0.65      0.27      0.39       401\n",
            "          22       0.52      0.18      0.27       210\n",
            "\n",
            "   micro avg       0.61      0.43      0.50     19370\n",
            "   macro avg       0.51      0.28      0.35     19370\n",
            "weighted avg       0.57      0.43      0.48     19370\n",
            " samples avg       0.60      0.48      0.49     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 17999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-17999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 12, Step: 17999, Train Loss: 0.0015, Valid Loss: 0.4154\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-17999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-17999/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11642518271573278\n",
            "Precision: 0.5246426046019844\n",
            "Recall: 0.2885001376216862\n",
            "F1-Score: 0.3470717729065751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.44      0.49      1044\n",
            "           1       0.53      0.29      0.38       821\n",
            "           2       0.79      0.44      0.57       306\n",
            "           3       0.33      0.05      0.08       411\n",
            "           4       0.61      0.55      0.58      2611\n",
            "           5       0.49      0.40      0.44      1163\n",
            "           6       0.74      0.40      0.52       629\n",
            "           7       0.67      0.76      0.71      4142\n",
            "           8       0.76      0.31      0.44       518\n",
            "           9       0.51      0.17      0.25       585\n",
            "          10       0.18      0.05      0.08       102\n",
            "          11       0.40      0.07      0.12       345\n",
            "          12       0.66      0.47      0.55       825\n",
            "          13       0.37      0.07      0.12       311\n",
            "          14       0.35      0.05      0.09       253\n",
            "          15       0.37      0.23      0.28       617\n",
            "          16       0.40      0.36      0.38      1590\n",
            "          17       0.58      0.37      0.45       586\n",
            "          18       0.71      0.08      0.15       142\n",
            "          19       0.46      0.09      0.16       191\n",
            "          20       0.50      0.54      0.52      1567\n",
            "          21       0.61      0.25      0.35       401\n",
            "          22       0.51      0.19      0.27       210\n",
            "\n",
            "   micro avg       0.58      0.45      0.51     19370\n",
            "   macro avg       0.52      0.29      0.35     19370\n",
            "weighted avg       0.56      0.45      0.48     19370\n",
            " samples avg       0.58      0.50      0.50     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 20999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-20999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 14, Step: 20999, Train Loss: 0.0009, Valid Loss: 0.4685\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-20999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-20999/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11886139248621617\n",
            "Precision: 0.5154689347316644\n",
            "Recall: 0.2922518302948243\n",
            "F1-Score: 0.35252011090212176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.46      0.50      1044\n",
            "           1       0.53      0.32      0.40       821\n",
            "           2       0.77      0.45      0.57       306\n",
            "           3       0.23      0.06      0.10       411\n",
            "           4       0.59      0.61      0.60      2611\n",
            "           5       0.52      0.38      0.44      1163\n",
            "           6       0.66      0.53      0.59       629\n",
            "           7       0.69      0.72      0.70      4142\n",
            "           8       0.74      0.32      0.45       518\n",
            "           9       0.48      0.17      0.25       585\n",
            "          10       0.12      0.02      0.03       102\n",
            "          11       0.34      0.06      0.11       345\n",
            "          12       0.65      0.50      0.56       825\n",
            "          13       0.32      0.07      0.12       311\n",
            "          14       0.44      0.09      0.16       253\n",
            "          15       0.40      0.16      0.23       617\n",
            "          16       0.42      0.33      0.37      1590\n",
            "          17       0.58      0.36      0.44       586\n",
            "          18       0.68      0.09      0.16       142\n",
            "          19       0.45      0.13      0.20       191\n",
            "          20       0.55      0.42      0.48      1567\n",
            "          21       0.60      0.26      0.36       401\n",
            "          22       0.54      0.19      0.28       210\n",
            "\n",
            "   micro avg       0.59      0.45      0.51     19370\n",
            "   macro avg       0.52      0.29      0.35     19370\n",
            "weighted avg       0.57      0.45      0.48     19370\n",
            " samples avg       0.59      0.50      0.50     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 23999...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/Model/Models-Train-24/checkpoint-23999/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 16, Step: 23999, Train Loss: 0.0008, Valid Loss: 0.5301\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/Model/Models-Train-24/checkpoint-23999/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-24/checkpoint-23999/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11988716502115655\n",
            "Precision: 0.5309260999451083\n",
            "Recall: 0.2725081127351647\n",
            "F1-Score: 0.33858447221893156\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.33      0.43      1044\n",
            "           1       0.57      0.27      0.37       821\n",
            "           2       0.80      0.41      0.54       306\n",
            "           3       0.25      0.05      0.09       411\n",
            "           4       0.58      0.61      0.60      2611\n",
            "           5       0.51      0.41      0.45      1163\n",
            "           6       0.70      0.45      0.55       629\n",
            "           7       0.66      0.80      0.72      4142\n",
            "           8       0.74      0.30      0.42       518\n",
            "           9       0.44      0.20      0.28       585\n",
            "          10       0.15      0.02      0.03       102\n",
            "          11       0.33      0.06      0.10       345\n",
            "          12       0.69      0.43      0.53       825\n",
            "          13       0.34      0.10      0.15       311\n",
            "          14       0.41      0.08      0.14       253\n",
            "          15       0.40      0.18      0.25       617\n",
            "          16       0.43      0.29      0.35      1590\n",
            "          17       0.66      0.30      0.41       586\n",
            "          18       0.67      0.10      0.17       142\n",
            "          19       0.50      0.08      0.14       191\n",
            "          20       0.56      0.39      0.46      1567\n",
            "          21       0.65      0.23      0.34       401\n",
            "          22       0.57      0.18      0.27       210\n",
            "\n",
            "   micro avg       0.59      0.44      0.51     19370\n",
            "   macro avg       0.53      0.27      0.34     19370\n",
            "weighted avg       0.57      0.44      0.48     19370\n",
            " samples avg       0.60      0.50      0.50     19370\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ViTForImageClassification.from_pretrained(f\"/content/checkpoint-999\").to(device)\n",
        "# image_processor = ViTImageProcessor.from_pretrained(f\"/content/checkpoint-999\")"
      ],
      "metadata": {
        "id": "tHqcBHpmv2iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zm9NW-b1ak-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-JJINar35a3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}