{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/MultiModel/blob/master/Train_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LhpxluXAy0g"
      },
      "outputs": [],
      "source": [
        "!pip install transformers evaluate datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBq4mm7cA4Cp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import *\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlLN5LTVA5eJ"
      },
      "outputs": [],
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Custom Dataset using `ImageFolder`\n"
      ],
      "metadata": {
        "id": "H9ZcQf_HDXl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds_train = load_dataset(\"imagefolder\", data_dir=\"/content/Dataset(s)/jointHF-train+test_unseen/train\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ee460739db59498389b0985af09972e9",
            "40bddc3c79af4acf81a07478f015ec1a",
            "5f66e076397047b3aa37d7e77f9244d6",
            "3ed3e4eff0f44b219f59207aca60459d",
            "cd2d2df0baeb4945b75ee057d8539948",
            "b334723df3f94c91b90df526dd50cecc",
            "4153b7b98b804e2e932ccd341fc81fb6",
            "868d3b9423fa46719188ef2e79434c44",
            "fd7d66ffe3124838aaf82c0a26e8ed4b",
            "34d091d753724cf6bcef08f3e4606013",
            "56d7e65f89fa4c0fa6b936c1830e40d1"
          ]
        },
        "id": "LjzUza9MwBgz",
        "outputId": "27e916c5-654e-48cb-a710-4d15fd85f5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/19000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee460739db59498389b0985af09972e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4XZ4n1HmAjY",
        "outputId": "65663c6d-4fa3-4846-a4e1-7a0d382f45b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 19000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = load_dataset(\"imagefolder\", data_dir=\"/content/Dataset(s)/jointHF-train+test_unseen/test\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "1efee0dd3ad34561aedcea57f2820cec",
            "617d0125353848b5b507505f9839be11",
            "6e4ea9dd3d684fab81014a253f8dc24e",
            "08315a696d1d45218df98fde056b99c0",
            "270a30e0df8c4dd0abd4bb67f284e6f5",
            "e0a59f841055478396e596aa7ba322df",
            "e9f2ada2486240abbd8c4f92e0e861cf",
            "c684050d5f074e5a8762554db8bfc9dc",
            "3b9303bb023f4c059a3ce6230f834b8c",
            "55cff02a2f4e457aa75811059c00b3d6",
            "f4498fe0320c47369fb2cc5c1265e257"
          ]
        },
        "id": "P4lAGXMWk-m3",
        "outputId": "df77ebae-f9f1-4b67-9849-a27d0ce77586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/4000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1efee0dd3ad34561aedcea57f2820cec"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN7oyy7Jm0lq",
        "outputId": "95485752-82f2-4798-97a3-1df75c263bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 4000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "aLyKHM-Oj0bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use _3.png for Filtering out Encoded Images\n",
        "# Use _4.png for Filtering out Just Images\n",
        "\n",
        "import os\n",
        "def filter_funtion(example):\n",
        "    img = example[\"image\"]\n",
        "    filename = os.path.basename(img.filename)\n",
        "\n",
        "    return filename.endswith(\"_4.png\")"
      ],
      "metadata": {
        "id": "yEflYIqPj01W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_train.filter(filter_funtion)"
      ],
      "metadata": {
        "id": "ofF8M3Ajj2vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = ds_val.filter(filter_funtion)"
      ],
      "metadata": {
        "id": "aiMn7wvWj8o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the Data"
      ],
      "metadata": {
        "id": "QVjb_p9kDr5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgxqXVVrITqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614f9c35-4873-4b01-b92f-2156e0afef58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(names=['0', '1'], id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "labels = ds_train.features[\"label\"]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozNlqVN3IgnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935283a9-3471-4754-f4d3-ef2cfa4569d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "labels.int2str(ds_train[532][\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the Data"
      ],
      "metadata": {
        "id": "W8jdhJCQKCOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x5QuhV8IwXB"
      },
      "outputs": [],
      "source": [
        "def transform(examples):\n",
        "  # convert all images to RGB format, then preprocessing it\n",
        "  # using our image processor\n",
        "  inputs = image_processor([img.convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  # we also shouldn't forget about the labels\n",
        "  inputs[\"labels\"] = examples[\"label\"]\n",
        "  return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY7oXLDZJBaX"
      },
      "outputs": [],
      "source": [
        "# use the with_transform() method to apply the transform to the dataset on the fly during training\n",
        "train_dataset = ds_train.with_transform(transform)\n",
        "val_dataset = ds_val.with_transform(transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbWrF63YQdsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7afdfc5-2994-40e1-f72d-68b6bab99716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for item in train_dataset:\n",
        "  print(item[\"pixel_values\"].shape)\n",
        "  print(item[\"labels\"])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnrUwcqwKTOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385aa950-38cd-4253-fa98-78805819a10d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# extract the labels for our dataset\n",
        "labels = ds_train.features[\"label\"].names\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUukexdrJGob"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
        "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNg1HnXTteYK",
        "outputId": "970f305d-e4e5-4b50-814f-37a838100c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 9500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbnt3V9ntfhJ",
        "outputId": "8e7683b3-33a5-47d8-96ed-c63cb7049333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Metrics"
      ],
      "metadata": {
        "id": "mNT_iBYyKGAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crXIbHCeJYFs"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# load the accuracy and f1 metrics from the evaluate module\n",
        "accuracy = load(\"accuracy\")\n",
        "f1 = load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  # compute the accuracy and f1 scores & return them\n",
        "  accuracy_score = accuracy.compute(predictions=np.argmax(eval_pred.predictions, axis=1), references=eval_pred.label_ids)\n",
        "  f1_score = f1.compute(predictions=np.argmax(eval_pred.predictions, axis=1), references=eval_pred.label_ids, average=\"macro\")\n",
        "\n",
        "  auroc_score = roc_auc_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1))\n",
        "  print(f\"AUROC Score: {auroc_score:.4f}\")\n",
        "\n",
        "  return {**accuracy_score, **f1_score}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "2WNJaZeYKJZH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1MmFNVLKw_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b6412a-95ff-4a64-9b46-7c0f0da9f81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/3f49326eb077187dfe1c2a2bb15fbd74e6ab91e3/config.json\n",
            "Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
            "  \"architectures\": [\n",
            "    \"ViTForImageClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"0\",\n",
            "    \"1\": \"1\"\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"0\": \"0\",\n",
            "    \"1\": \"1\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.32.1\"\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/3f49326eb077187dfe1c2a2bb15fbd74e6ab91e3/model.safetensors\n",
            "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
            "\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# load the ViT model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(labels),\n",
        "    id2label={str(i): c for i, c in enumerate(labels)},\n",
        "    label2id={c: str(i) for i, c in enumerate(labels)},\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install accelerate -U"
      ],
      "metadata": {
        "id": "ojq7BsY6cbCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers[torch]"
      ],
      "metadata": {
        "id": "gIOh_AB-cmS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNnG1GUUK7nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6485e605-bf54-46cf-fc04-1e301a5a318e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"/content/Model/Models-Train-20\", # output directory\n",
        "  per_device_train_batch_size=32, # batch size per device during training\n",
        "  evaluation_strategy=\"steps\",    # evaluation strategy to adopt during training\n",
        "  num_train_epochs=20,             # total number of training epochs\n",
        "  # fp16=True,                    # use mixed precision\n",
        "  save_steps=1180,                # number of update steps before saving checkpoint\n",
        "  eval_steps=1180,                # number of update steps before evaluating\n",
        "  logging_steps=1180,             # number of update steps before logging\n",
        "  # save_steps=50,\n",
        "  # eval_steps=50,\n",
        "  # logging_steps=50,\n",
        "  save_total_limit=4,             # limit the total amount of checkpoints on disk\n",
        "  remove_unused_columns=False,    # remove unused columns from the dataset\n",
        "  push_to_hub=False,              # do not push the model to the hub\n",
        "  report_to='tensorboard',        # report metrics to tensorboard\n",
        "  load_best_model_at_end=True,    # load the best model at the end of training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASOtjmcHdc2R",
        "outputId": "aa19dbbd-c174-4872-e0fd-bb26d054426d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 9500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3M13NlzsyNT",
        "outputId": "593fbf37-e53f-4f39-c7d6-6cd09d9d74a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n8Cv48_QKzr"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                        # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                 # training arguments, defined above\n",
        "    data_collator=collate_fn,           # the data collator that will be used for batching\n",
        "    compute_metrics=compute_metrics,    # the metrics function that will be used for evaluation\n",
        "    train_dataset=train_dataset,        # training dataset\n",
        "    eval_dataset=val_dataset,           # evaluation dataset\n",
        "    tokenizer=image_processor,          # the processor that will be used for preprocessing the images\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wUUoQyh-QPED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "159c9915-edf2-4ac0-b7db-5d31db6ee826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 9,500\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5,940\n",
            "  Number of trainable parameters = 85,800,194\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5940' max='5940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5940/5940 2:27:24, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.488800</td>\n",
              "      <td>0.662210</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.670567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.087200</td>\n",
              "      <td>1.274229</td>\n",
              "      <td>0.726500</td>\n",
              "      <td>0.715515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3540</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>1.649989</td>\n",
              "      <td>0.728500</td>\n",
              "      <td>0.718387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4720</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>1.821757</td>\n",
              "      <td>0.725500</td>\n",
              "      <td>0.715163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.860298</td>\n",
              "      <td>0.725500</td>\n",
              "      <td>0.715163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC Score: 0.6816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/Model/Models-Train-20/checkpoint-1180\n",
            "Configuration saved in /content/Model/Models-Train-20/checkpoint-1180/config.json\n",
            "Model weights saved in /content/Model/Models-Train-20/checkpoint-1180/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-20/checkpoint-1180/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC Score: 0.7225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/Model/Models-Train-20/checkpoint-2360\n",
            "Configuration saved in /content/Model/Models-Train-20/checkpoint-2360/config.json\n",
            "Model weights saved in /content/Model/Models-Train-20/checkpoint-2360/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-20/checkpoint-2360/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC Score: 0.7265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/Model/Models-Train-20/checkpoint-3540\n",
            "Configuration saved in /content/Model/Models-Train-20/checkpoint-3540/config.json\n",
            "Model weights saved in /content/Model/Models-Train-20/checkpoint-3540/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-20/checkpoint-3540/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC Score: 0.7231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/Model/Models-Train-20/checkpoint-4720\n",
            "Configuration saved in /content/Model/Models-Train-20/checkpoint-4720/config.json\n",
            "Model weights saved in /content/Model/Models-Train-20/checkpoint-4720/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-20/checkpoint-4720/preprocessor_config.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC Score: 0.7231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/Model/Models-Train-20/checkpoint-5900\n",
            "Configuration saved in /content/Model/Models-Train-20/checkpoint-5900/config.json\n",
            "Model weights saved in /content/Model/Models-Train-20/checkpoint-5900/pytorch_model.bin\n",
            "Image processor saved in /content/Model/Models-Train-20/checkpoint-5900/preprocessor_config.json\n",
            "Deleting older checkpoint [/content/Model/Models-Train-20/checkpoint-2360] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/Model/Models-Train-20/checkpoint-1180 (score: 0.66221022605896).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5940, training_loss=0.1157257354892759, metrics={'train_runtime': 8848.338, 'train_samples_per_second': 21.473, 'train_steps_per_second': 0.671, 'total_flos': 1.472347802677248e+19, 'train_loss': 0.1157257354892759, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akZ0-H5YQSuJ"
      },
      "outputs": [],
      "source": [
        "# trainer.evaluate(dataset[\"test\"])\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2xd0XJYKZU5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil, os\n",
        "\n",
        "# # Define the source folder path (in Colab)\n",
        "# source_folder_path = '/content/output/checkpoint-7000'\n",
        "\n",
        "# # Define the destination folder path (in Google Drive)\n",
        "# destination_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Hateful-Memes/Vit/checkpoint-7000\"\n",
        "\n",
        "# # Remove the existing destination folder (if it exists)\n",
        "# if os.path.exists(destination_folder_path):\n",
        "#     shutil.rmtree(destination_folder_path)\n",
        "\n",
        "# # Copy the folder\n",
        "# shutil.copytree(source_folder_path, destination_folder_path)"
      ],
      "metadata": {
        "id": "pY4jH2jyVc7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAZFCk5Gd1p0"
      },
      "outputs": [],
      "source": [
        "# # start tensorboard\n",
        "# # %load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir /content/Model/Models-Train-15/runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_SsuMpFafPe"
      },
      "source": [
        "## Alternatively: Training using PyTorch Loop\n",
        "Run the two below cells to fine-tune using a regular PyTorch loop if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C29idUGDd2yW"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset_loader = DataLoader(dataset[\"train\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset_loader = DataLoader(dataset[\"validation\"], collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "log_dir = \"./image-classification/tensorboard\"\n",
        "summary_writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "num_epochs = 3\n",
        "model = model.to(device)\n",
        "# print some statistics before training\n",
        "# number of training steps\n",
        "n_train_steps = num_epochs * len(train_dataset_loader)\n",
        "# number of validation steps\n",
        "n_valid_steps = len(valid_dataset_loader)\n",
        "# current training step\n",
        "current_step = 0\n",
        "# logging, eval & save steps\n",
        "save_steps = 1000\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  accuracy_score = accuracy.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
        "  f1_score = f1.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids, average=\"macro\")\n",
        "  return {**accuracy_score, **f1_score}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v6dNtUcd7-G"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # set the model to training mode\n",
        "    model.train()\n",
        "    # initialize the training loss\n",
        "    train_loss = 0\n",
        "    # initialize the progress bar\n",
        "    progress_bar = tqdm(range(current_step, n_train_steps), \"Training\", dynamic_ncols=True, ncols=80)\n",
        "    for batch in train_dataset_loader:\n",
        "      if (current_step+1) % save_steps == 0:\n",
        "        ### evaluation code ###\n",
        "        # evaluate on the validation set\n",
        "        # if the current step is a multiple of the save steps\n",
        "        print()\n",
        "        print(f\"Validation at step {current_step}...\")\n",
        "        print()\n",
        "        # set the model to evaluation mode\n",
        "        model.eval()\n",
        "        # initialize our lists that store the predictions and the labels\n",
        "        predictions, labels = [], []\n",
        "        # initialize the validation loss\n",
        "        valid_loss = 0\n",
        "        for batch in valid_dataset_loader:\n",
        "            # get the batch\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            label_ids = batch[\"labels\"].to(device)\n",
        "            # forward pass\n",
        "            outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
        "            # get the loss\n",
        "            loss = outputs.loss\n",
        "            valid_loss += loss.item()\n",
        "            # free the GPU memory\n",
        "            logits = outputs.logits.detach().cpu()\n",
        "            # add the predictions to the list\n",
        "            predictions.extend(logits.argmax(dim=-1).tolist())\n",
        "            # add the labels to the list\n",
        "            labels.extend(label_ids.tolist())\n",
        "        # make the EvalPrediction object that the compute_metrics function expects\n",
        "        eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
        "        # compute the metrics\n",
        "        metrics = compute_metrics(eval_prediction)\n",
        "        # print the stats\n",
        "        print()\n",
        "        print(f\"Epoch: {epoch}, Step: {current_step}, Train Loss: {train_loss / save_steps:.4f}, \" +\n",
        "              f\"Valid Loss: {valid_loss / n_valid_steps:.4f}, Accuracy: {metrics['accuracy']}, \" +\n",
        "              f\"F1 Score: {metrics['f1']}\")\n",
        "        print()\n",
        "        # log the metrics\n",
        "        summary_writer.add_scalar(\"valid_loss\", valid_loss / n_valid_steps, global_step=current_step)\n",
        "        summary_writer.add_scalar(\"accuracy\", metrics[\"accuracy\"], global_step=current_step)\n",
        "        summary_writer.add_scalar(\"f1\", metrics[\"f1\"], global_step=current_step)\n",
        "        # save the model\n",
        "        model.save_pretrained(f\"./vit-base-food/checkpoint-{current_step}\")\n",
        "        image_processor.save_pretrained(f\"./vit-base-food/checkpoint-{current_step}\")\n",
        "        # get the model back to train mode\n",
        "        model.train()\n",
        "        # reset the train and valid loss\n",
        "        train_loss, valid_loss = 0, 0\n",
        "      ### training code below ###\n",
        "      # get the batch & convert to tensor\n",
        "      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device)\n",
        "      # forward pass\n",
        "      outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "      # get the loss\n",
        "      loss = outputs.loss\n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      # update the weights\n",
        "      optimizer.step()\n",
        "      # zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "      # log the loss\n",
        "      loss_v = loss.item()\n",
        "      train_loss += loss_v\n",
        "      # increment the step\n",
        "      current_step += 1\n",
        "      progress_bar.update(1)\n",
        "      # log the training loss\n",
        "      summary_writer.add_scalar(\"train_loss\", loss_v, global_step=current_step)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mNT_iBYyKGAE",
        "H_SsuMpFafPe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee460739db59498389b0985af09972e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40bddc3c79af4acf81a07478f015ec1a",
              "IPY_MODEL_5f66e076397047b3aa37d7e77f9244d6",
              "IPY_MODEL_3ed3e4eff0f44b219f59207aca60459d"
            ],
            "layout": "IPY_MODEL_cd2d2df0baeb4945b75ee057d8539948"
          }
        },
        "40bddc3c79af4acf81a07478f015ec1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b334723df3f94c91b90df526dd50cecc",
            "placeholder": "​",
            "style": "IPY_MODEL_4153b7b98b804e2e932ccd341fc81fb6",
            "value": "Resolving data files: 100%"
          }
        },
        "5f66e076397047b3aa37d7e77f9244d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_868d3b9423fa46719188ef2e79434c44",
            "max": 19000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd7d66ffe3124838aaf82c0a26e8ed4b",
            "value": 19000
          }
        },
        "3ed3e4eff0f44b219f59207aca60459d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34d091d753724cf6bcef08f3e4606013",
            "placeholder": "​",
            "style": "IPY_MODEL_56d7e65f89fa4c0fa6b936c1830e40d1",
            "value": " 19000/19000 [00:00&lt;00:00, 109308.16it/s]"
          }
        },
        "cd2d2df0baeb4945b75ee057d8539948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b334723df3f94c91b90df526dd50cecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4153b7b98b804e2e932ccd341fc81fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "868d3b9423fa46719188ef2e79434c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7d66ffe3124838aaf82c0a26e8ed4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34d091d753724cf6bcef08f3e4606013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d7e65f89fa4c0fa6b936c1830e40d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efee0dd3ad34561aedcea57f2820cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_617d0125353848b5b507505f9839be11",
              "IPY_MODEL_6e4ea9dd3d684fab81014a253f8dc24e",
              "IPY_MODEL_08315a696d1d45218df98fde056b99c0"
            ],
            "layout": "IPY_MODEL_270a30e0df8c4dd0abd4bb67f284e6f5"
          }
        },
        "617d0125353848b5b507505f9839be11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0a59f841055478396e596aa7ba322df",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f2ada2486240abbd8c4f92e0e861cf",
            "value": "Resolving data files: 100%"
          }
        },
        "6e4ea9dd3d684fab81014a253f8dc24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c684050d5f074e5a8762554db8bfc9dc",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b9303bb023f4c059a3ce6230f834b8c",
            "value": 4000
          }
        },
        "08315a696d1d45218df98fde056b99c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55cff02a2f4e457aa75811059c00b3d6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4498fe0320c47369fb2cc5c1265e257",
            "value": " 4000/4000 [00:00&lt;00:00,  7.63it/s]"
          }
        },
        "270a30e0df8c4dd0abd4bb67f284e6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a59f841055478396e596aa7ba322df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f2ada2486240abbd8c4f92e0e861cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c684050d5f074e5a8762554db8bfc9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9303bb023f4c059a3ce6230f834b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55cff02a2f4e457aa75811059c00b3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4498fe0320c47369fb2cc5c1265e257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}