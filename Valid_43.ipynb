{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/MultiModel/blob/master/Valid_43.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ObgVtPmABT7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "pziXvdPgU58B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86000255-5118-4496-a9e6-a4ba4c68bf43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "8EPDp91Tyicv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Validation Dataset and Preprocessing"
      ],
      "metadata": {
        "id": "p3yzu25SYhKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save_dir = '/content/Model/Fused_ResNetmodel_Hatefull_Experiment#5'\n",
        "# load_path = os.path.join(save_dir, 'model.pth')\n",
        "\n",
        "# # Create an instance of the ResNet model\n",
        "# resnet = torchvision.models.resnet101(pretrained=False)\n",
        "# resnet.fc = nn.Linear(2048, 2) # Choose the number of output classses as per your model\n",
        "\n",
        "# # Load the saved model parameters\n",
        "# # resnet.load_state_dict(torch.load(load_path, map_location=torch.device('cpu')))\n",
        "# resnet.load_state_dict(torch.load(load_path))\n",
        "\n",
        "# # Set the model to evaluation mode and respective device\n",
        "# resnet.eval()\n",
        "# resnet.to(device)"
      ],
      "metadata": {
        "id": "6gITvuS1n91U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "4ElOxuNZvqLy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset = datasets.ImageFolder(data_dir, transform=val_transform)\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "ZEqVuNvcMgvo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valPath = \"/content/Dataset(s)/fused-ferramenta-val\"\n",
        "val_dataset = ValidationDataset(valPath)"
      ],
      "metadata": {
        "id": "4UfrxOQ3sCgB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "validation_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8e-uQ6lqVhmI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(val_dataset))\n",
        "print(\"Number of classes:\", len(val_dataset.classes))"
      ],
      "metadata": {
        "id": "oShp-fOcVmYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73249900-f7e0-486e-def9-2d1d7d5ef2e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 21869\n",
            "Number of classes: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = len(validation_data_loader)\n",
        "print(\"Number of batches:\", num_batches)"
      ],
      "metadata": {
        "id": "l_2_YsDRCJL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2a6f14-fde6-415a-8996-63eb35599d13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches: 684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "RbwN0R_b2tMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 1\n",
        "save_dir = '/content/Model/Models-Train-10'\n",
        "while epoch < 27:\n",
        "    model_name = str(epoch+1) + \"_model.pth\"\n",
        "    load_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "    # Create an instance of the ResNet model\n",
        "    resnet = torchvision.models.resnet101(pretrained=False)\n",
        "    resnet.fc = nn.Linear(2048, 52) # Choose the number of output classses as per your model\n",
        "\n",
        "    # Load the saved model parameters\n",
        "    # resnet.load_state_dict(torch.load(load_path, map_location=torch.device('cpu')))\n",
        "    resnet.load_state_dict(torch.load(load_path))\n",
        "\n",
        "    # Set the model to evaluation mode and respective device\n",
        "    resnet.eval()\n",
        "    resnet.to(device)\n",
        "\n",
        "    # resnet.eval()\n",
        "\n",
        "    predicted_classes = []\n",
        "    actual_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_data_loader:\n",
        "            # Move the images and labels to the GPU if available\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet(images)\n",
        "\n",
        "            # Get the predicted labels\n",
        "            _, predicted_label = torch.max(outputs, 1)\n",
        "\n",
        "            # Store the predicted and true labels\n",
        "            predicted_classes.extend(predicted_label.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        accuracy = accuracy_score(actual_labels, predicted_classes)\n",
        "        precision = precision_score(actual_labels, predicted_classes, average='weighted')\n",
        "        recall = recall_score(actual_labels, predicted_classes, average='weighted')\n",
        "        f1 = f1_score(actual_labels, predicted_classes, average='weighted')\n",
        "\n",
        "        print(\"Result with model \" + model_name + \" : \")\n",
        "        print(\"=========================================\")\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1-score:\", f1)\n",
        "        print(classification_report(actual_labels, predicted_classes))\n",
        "\n",
        "        predicted_classes = np.array(predicted_classes)\n",
        "        actual_labels = np.array(actual_labels)\n",
        "\n",
        "        # Calculate the AUROC score\n",
        "        # auroc = roc_auc_score(actual_labels, predicted_classes)\n",
        "        # print(\"AUROC:\", auroc)\n",
        "        epoch = epoch + 1\n"
      ],
      "metadata": {
        "id": "QYxUnUjO7DOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5815022-6a2e-41ba-dfbe-1438d4673108"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 2_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9570625085737803\n",
            "Precision: 0.9571563447215355\n",
            "Recall: 0.9570625085737803\n",
            "F1-score: 0.9568593710671013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.63      0.70        59\n",
            "           1       0.97      0.98      0.98      1879\n",
            "           2       0.97      0.99      0.98       345\n",
            "           3       1.00      0.98      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.91      0.93      0.92       176\n",
            "           6       0.98      0.99      0.98      1069\n",
            "           7       0.96      0.95      0.96       148\n",
            "           8       0.97      0.97      0.97       663\n",
            "           9       0.99      0.99      0.99       642\n",
            "          10       0.94      0.96      0.95       136\n",
            "          11       0.94      0.97      0.96        35\n",
            "          12       0.82      0.96      0.89       112\n",
            "          13       0.96      0.97      0.97       842\n",
            "          14       0.97      0.98      0.98      1555\n",
            "          15       0.93      0.78      0.85        36\n",
            "          16       0.96      0.90      0.93        51\n",
            "          17       0.86      0.97      0.91       206\n",
            "          18       0.95      0.93      0.94        59\n",
            "          19       0.72      0.72      0.72        43\n",
            "          20       0.89      0.97      0.93        33\n",
            "          21       0.88      0.83      0.85      1926\n",
            "          22       0.94      0.97      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.96      0.97       270\n",
            "          25       0.98      0.96      0.97       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.99      0.99       695\n",
            "          29       0.93      0.93      0.93       146\n",
            "          30       0.93      0.87      0.90        85\n",
            "          31       0.88      0.94      0.91       331\n",
            "          32       0.98      0.94      0.96        54\n",
            "          33       0.93      0.93      0.93      1196\n",
            "          34       0.97      0.96      0.97        73\n",
            "          35       0.86      0.93      0.90       148\n",
            "          36       0.95      0.98      0.96       238\n",
            "          37       0.99      0.95      0.97       146\n",
            "          38       0.99      1.00      0.99       142\n",
            "          39       1.00      1.00      1.00       327\n",
            "          40       0.91      0.90      0.90       203\n",
            "          41       0.99      0.97      0.98       522\n",
            "          42       0.91      0.96      0.93       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.96       254\n",
            "          45       0.89      0.86      0.88        37\n",
            "          46       0.85      0.95      0.90        80\n",
            "          47       0.88      0.85      0.87       116\n",
            "          48       0.91      0.96      0.93       379\n",
            "          49       0.93      0.92      0.92       159\n",
            "          50       0.96      0.99      0.98       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 3_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9591202158306278\n",
            "Precision: 0.9590558958734685\n",
            "Recall: 0.9591202158306278\n",
            "F1-score: 0.9586568199527834\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.69      0.74        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.97      0.99      0.98       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.95      1.00      0.97       132\n",
            "           5       0.92      0.89      0.90       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.97      0.96      0.96       148\n",
            "           8       0.97      0.99      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.95      0.96      0.95       136\n",
            "          11       0.81      0.97      0.88        35\n",
            "          12       0.88      0.96      0.91       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.86      0.69      0.77        36\n",
            "          16       0.98      0.92      0.95        51\n",
            "          17       0.89      0.96      0.93       206\n",
            "          18       0.93      0.97      0.95        59\n",
            "          19       0.83      0.79      0.81        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.91      0.82      0.86      1926\n",
            "          22       0.95      0.97      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.96      0.98       270\n",
            "          25       0.96      0.97      0.97       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.96      0.99      0.97       697\n",
            "          28       0.99      0.99      0.99       695\n",
            "          29       0.90      0.97      0.94       146\n",
            "          30       0.86      0.96      0.91        85\n",
            "          31       0.96      0.88      0.92       331\n",
            "          32       0.98      0.91      0.94        54\n",
            "          33       0.92      0.94      0.93      1196\n",
            "          34       0.95      0.97      0.96        73\n",
            "          35       0.86      0.95      0.90       148\n",
            "          36       0.96      1.00      0.98       238\n",
            "          37       0.98      0.97      0.98       146\n",
            "          38       0.99      1.00      0.99       142\n",
            "          39       0.99      1.00      1.00       327\n",
            "          40       0.90      0.94      0.92       203\n",
            "          41       0.96      0.98      0.97       522\n",
            "          42       0.89      0.95      0.92       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.93      0.95      0.94       254\n",
            "          45       0.94      0.86      0.90        37\n",
            "          46       0.89      0.91      0.90        80\n",
            "          47       0.91      0.84      0.87       116\n",
            "          48       0.93      0.95      0.94       379\n",
            "          49       0.87      0.99      0.92       159\n",
            "          50       0.92      1.00      0.96       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.95      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 4_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9594403036261374\n",
            "Precision: 0.959339640324557\n",
            "Recall: 0.9594403036261374\n",
            "F1-score: 0.9590822471036367\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.59      0.69        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.95      0.98      0.96       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.92      0.99      0.96       132\n",
            "           5       0.91      0.91      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.98      0.97      0.98       663\n",
            "           9       0.98      0.99      0.99       642\n",
            "          10       0.88      0.99      0.93       136\n",
            "          11       0.94      0.94      0.94        35\n",
            "          12       0.85      0.95      0.90       112\n",
            "          13       0.96      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.79      0.75      0.77        36\n",
            "          16       0.94      0.94      0.94        51\n",
            "          17       0.90      0.96      0.92       206\n",
            "          18       0.93      0.95      0.94        59\n",
            "          19       0.79      0.77      0.78        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.89      0.84      0.87      1926\n",
            "          22       0.95      0.98      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.97      0.98       270\n",
            "          25       0.97      0.95      0.96       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.98      0.99      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.94      0.90      0.92       146\n",
            "          30       0.95      0.92      0.93        85\n",
            "          31       0.92      0.93      0.92       331\n",
            "          32       0.98      0.89      0.93        54\n",
            "          33       0.94      0.94      0.94      1196\n",
            "          34       0.89      0.99      0.94        73\n",
            "          35       0.91      0.95      0.93       148\n",
            "          36       0.93      0.99      0.96       238\n",
            "          37       0.95      0.95      0.95       146\n",
            "          38       0.98      1.00      0.99       142\n",
            "          39       0.99      1.00      1.00       327\n",
            "          40       0.89      0.97      0.93       203\n",
            "          41       0.97      0.99      0.98       522\n",
            "          42       0.93      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.96      0.96      0.96       254\n",
            "          45       0.93      0.73      0.82        37\n",
            "          46       0.88      0.93      0.90        80\n",
            "          47       0.95      0.80      0.87       116\n",
            "          48       0.92      0.93      0.93       379\n",
            "          49       0.90      0.94      0.92       159\n",
            "          50       0.97      0.98      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 5_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9601719328730166\n",
            "Precision: 0.9602703319869261\n",
            "Recall: 0.9601719328730166\n",
            "F1-score: 0.9599301816076377\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.61      0.67        59\n",
            "           1       0.97      0.98      0.98      1879\n",
            "           2       0.97      0.98      0.98       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.92      0.93      0.92       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.95      0.95      0.95       148\n",
            "           8       0.98      0.98      0.98       663\n",
            "           9       0.98      0.99      0.99       642\n",
            "          10       0.94      0.95      0.95       136\n",
            "          11       0.92      1.00      0.96        35\n",
            "          12       0.90      0.92      0.91       112\n",
            "          13       0.98      0.97      0.97       842\n",
            "          14       0.98      0.98      0.98      1555\n",
            "          15       0.83      0.81      0.82        36\n",
            "          16       0.96      0.94      0.95        51\n",
            "          17       0.89      0.98      0.94       206\n",
            "          18       0.98      0.95      0.97        59\n",
            "          19       0.81      0.88      0.84        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.90      0.84      0.87      1926\n",
            "          22       0.96      0.96      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.98      0.97      0.98       270\n",
            "          25       0.97      0.95      0.96       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.96      0.99      0.98       697\n",
            "          28       0.99      0.99      0.99       695\n",
            "          29       0.87      0.97      0.91       146\n",
            "          30       0.83      0.93      0.88        85\n",
            "          31       0.92      0.92      0.92       331\n",
            "          32       0.96      0.91      0.93        54\n",
            "          33       0.94      0.95      0.94      1196\n",
            "          34       0.90      0.96      0.93        73\n",
            "          35       0.90      0.95      0.92       148\n",
            "          36       0.95      0.99      0.97       238\n",
            "          37       0.98      0.96      0.97       146\n",
            "          38       0.99      1.00      0.99       142\n",
            "          39       0.99      0.99      0.99       327\n",
            "          40       0.89      0.95      0.92       203\n",
            "          41       0.98      0.97      0.98       522\n",
            "          42       0.92      0.94      0.93       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.94      0.95       254\n",
            "          45       1.00      0.78      0.88        37\n",
            "          46       0.86      0.91      0.88        80\n",
            "          47       0.89      0.84      0.86       116\n",
            "          48       0.93      0.94      0.93       379\n",
            "          49       0.82      0.95      0.88       159\n",
            "          50       0.99      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 6_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9607206548081759\n",
            "Precision: 0.9608650757744112\n",
            "Recall: 0.9607206548081759\n",
            "F1-score: 0.9606294742318433\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.63      0.65        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.96      0.99      0.97       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.97      0.98      0.97       132\n",
            "           5       0.93      0.89      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.94      0.96       148\n",
            "           8       0.98      0.98      0.98       663\n",
            "           9       0.98      0.99      0.99       642\n",
            "          10       0.93      0.96      0.94       136\n",
            "          11       1.00      0.97      0.99        35\n",
            "          12       0.85      0.94      0.89       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.93      0.75      0.83        36\n",
            "          16       0.96      0.92      0.94        51\n",
            "          17       0.94      0.93      0.94       206\n",
            "          18       0.96      0.93      0.95        59\n",
            "          19       0.80      0.77      0.79        43\n",
            "          20       0.91      0.94      0.93        33\n",
            "          21       0.88      0.87      0.88      1926\n",
            "          22       0.96      0.97      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.97      0.98      0.98       270\n",
            "          25       0.95      0.97      0.96       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       0.99      0.98      0.98       695\n",
            "          29       0.94      0.92      0.93       146\n",
            "          30       0.95      0.89      0.92        85\n",
            "          31       0.90      0.93      0.92       331\n",
            "          32       0.98      0.93      0.95        54\n",
            "          33       0.94      0.93      0.93      1196\n",
            "          34       0.92      0.96      0.94        73\n",
            "          35       0.90      0.95      0.92       148\n",
            "          36       0.96      1.00      0.98       238\n",
            "          37       0.95      0.97      0.96       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.91      0.94      0.92       203\n",
            "          41       0.98      0.97      0.98       522\n",
            "          42       0.95      0.89      0.92       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.94      0.97      0.95       254\n",
            "          45       0.89      0.86      0.88        37\n",
            "          46       0.83      0.96      0.89        80\n",
            "          47       0.96      0.82      0.88       116\n",
            "          48       0.92      0.97      0.94       379\n",
            "          49       0.92      0.94      0.93       159\n",
            "          50       0.92      1.00      0.96       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 7_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9586172207233984\n",
            "Precision: 0.9586451905631383\n",
            "Recall: 0.9586172207233984\n",
            "F1-score: 0.9582855583935348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.68      0.70        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.99      0.96      0.97       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.92      0.90      0.91       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.98      0.98      0.98       663\n",
            "           9       0.97      1.00      0.98       642\n",
            "          10       0.90      0.96      0.93       136\n",
            "          11       0.89      0.94      0.92        35\n",
            "          12       0.93      0.93      0.93       112\n",
            "          13       0.95      0.98      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.96      0.69      0.81        36\n",
            "          16       0.96      0.96      0.96        51\n",
            "          17       0.89      0.96      0.93       206\n",
            "          18       0.93      0.95      0.94        59\n",
            "          19       0.75      0.77      0.76        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.90      0.82      0.86      1926\n",
            "          22       0.97      0.96      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.97      0.98       270\n",
            "          25       0.95      0.96      0.96       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.99      0.97      0.98       697\n",
            "          28       0.99      0.99      0.99       695\n",
            "          29       0.93      0.93      0.93       146\n",
            "          30       0.94      0.93      0.93        85\n",
            "          31       0.92      0.89      0.91       331\n",
            "          32       1.00      0.87      0.93        54\n",
            "          33       0.91      0.95      0.93      1196\n",
            "          34       0.92      0.95      0.93        73\n",
            "          35       0.86      0.95      0.90       148\n",
            "          36       0.97      0.97      0.97       238\n",
            "          37       0.96      0.97      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.87      0.96      0.91       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.94      0.95      0.94       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.92      0.96      0.94       254\n",
            "          45       0.91      0.81      0.86        37\n",
            "          46       0.85      0.94      0.89        80\n",
            "          47       0.91      0.86      0.88       116\n",
            "          48       0.92      0.95      0.94       379\n",
            "          49       0.91      0.95      0.93       159\n",
            "          50       0.99      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 8_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9581599524440989\n",
            "Precision: 0.9584503216925931\n",
            "Recall: 0.9581599524440989\n",
            "F1-score: 0.9581027623692374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.59      0.70        59\n",
            "           1       0.97      0.99      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.96      0.99      0.98       132\n",
            "           5       0.91      0.91      0.91       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.96      0.95      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.92      0.94      0.93       136\n",
            "          11       0.90      1.00      0.95        35\n",
            "          12       0.88      0.96      0.92       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.90      0.75      0.82        36\n",
            "          16       0.98      0.90      0.94        51\n",
            "          17       0.94      0.93      0.94       206\n",
            "          18       0.95      0.97      0.96        59\n",
            "          19       0.84      0.74      0.79        43\n",
            "          20       0.94      0.94      0.94        33\n",
            "          21       0.85      0.87      0.86      1926\n",
            "          22       0.97      0.95      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.98      0.96      0.97       270\n",
            "          25       0.97      0.94      0.95       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.99      0.97      0.98       697\n",
            "          28       0.99      0.98      0.99       695\n",
            "          29       0.91      0.92      0.92       146\n",
            "          30       0.84      0.91      0.87        85\n",
            "          31       0.93      0.91      0.92       331\n",
            "          32       0.98      0.89      0.93        54\n",
            "          33       0.94      0.90      0.92      1196\n",
            "          34       0.93      0.96      0.95        73\n",
            "          35       0.94      0.89      0.91       148\n",
            "          36       0.97      0.95      0.96       238\n",
            "          37       0.98      0.98      0.98       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      1.00       327\n",
            "          40       0.90      0.94      0.92       203\n",
            "          41       0.98      0.97      0.98       522\n",
            "          42       0.95      0.94      0.95       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.95      0.96      0.95       254\n",
            "          45       0.91      0.84      0.87        37\n",
            "          46       0.83      0.91      0.87        80\n",
            "          47       0.91      0.86      0.88       116\n",
            "          48       0.94      0.94      0.94       379\n",
            "          49       0.91      0.94      0.93       159\n",
            "          50       0.95      0.99      0.97       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 9_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.959028762174768\n",
            "Precision: 0.9594013423682952\n",
            "Recall: 0.959028762174768\n",
            "F1-score: 0.9589296507237135\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.63      0.67        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.96      1.00      0.98       132\n",
            "           5       0.94      0.89      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.95      0.96      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      0.99      0.99       642\n",
            "          10       0.94      0.96      0.95       136\n",
            "          11       0.94      0.94      0.94        35\n",
            "          12       0.85      0.95      0.90       112\n",
            "          13       0.96      0.98      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.96      0.72      0.83        36\n",
            "          16       0.94      0.94      0.94        51\n",
            "          17       0.91      0.95      0.93       206\n",
            "          18       0.93      0.95      0.94        59\n",
            "          19       0.77      0.86      0.81        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.86      0.87      0.86      1926\n",
            "          22       0.96      0.95      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.93      0.99      0.96       270\n",
            "          25       0.96      0.96      0.96       196\n",
            "          26       0.98      0.94      0.96       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.93      0.93      0.93       146\n",
            "          30       0.93      0.92      0.92        85\n",
            "          31       0.95      0.92      0.93       331\n",
            "          32       0.98      0.89      0.93        54\n",
            "          33       0.95      0.89      0.92      1196\n",
            "          34       0.93      0.96      0.95        73\n",
            "          35       0.92      0.95      0.93       148\n",
            "          36       0.95      0.99      0.97       238\n",
            "          37       0.99      0.96      0.97       146\n",
            "          38       0.97      1.00      0.98       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.95      0.91      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.93      0.96      0.95       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.92      0.97      0.94       254\n",
            "          45       0.97      0.81      0.88        37\n",
            "          46       0.87      0.94      0.90        80\n",
            "          47       0.98      0.79      0.88       116\n",
            "          48       0.91      0.95      0.93       379\n",
            "          49       0.87      0.96      0.92       159\n",
            "          50       0.97      0.99      0.98       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 10_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9587544012071882\n",
            "Precision: 0.9585792873825256\n",
            "Recall: 0.9587544012071882\n",
            "F1-score: 0.9583638181834219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.59      0.65        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.96      0.99      0.97       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.95      1.00      0.97       132\n",
            "           5       0.93      0.92      0.93       176\n",
            "           6       0.98      0.99      0.98      1069\n",
            "           7       0.93      0.93      0.93       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.92      0.96      0.94       136\n",
            "          11       0.94      0.94      0.94        35\n",
            "          12       0.88      0.95      0.91       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.85      0.78      0.81        36\n",
            "          16       0.98      0.92      0.95        51\n",
            "          17       0.91      0.95      0.93       206\n",
            "          18       0.98      0.93      0.96        59\n",
            "          19       0.80      0.74      0.77        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.90      0.83      0.86      1926\n",
            "          22       0.97      0.95      0.96       281\n",
            "          23       0.99      0.99      0.99       634\n",
            "          24       0.98      0.98      0.98       270\n",
            "          25       0.95      0.95      0.95       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.90      0.95      0.93       146\n",
            "          30       0.91      0.88      0.90        85\n",
            "          31       0.93      0.91      0.92       331\n",
            "          32       0.98      0.91      0.94        54\n",
            "          33       0.91      0.95      0.93      1196\n",
            "          34       0.93      0.96      0.95        73\n",
            "          35       0.90      0.95      0.93       148\n",
            "          36       0.95      0.98      0.97       238\n",
            "          37       0.95      0.99      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.92      0.93      0.92       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.91      0.94      0.93       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.92      0.97      0.95       254\n",
            "          45       0.94      0.84      0.89        37\n",
            "          46       0.85      0.91      0.88        80\n",
            "          47       0.93      0.78      0.85       116\n",
            "          48       0.93      0.95      0.94       379\n",
            "          49       0.84      0.96      0.90       159\n",
            "          50       0.95      1.00      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 11_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9602633865288764\n",
            "Precision: 0.9599989487144087\n",
            "Recall: 0.9602633865288764\n",
            "F1-score: 0.9598512670742633\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.68      0.75        59\n",
            "           1       0.97      0.99      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.93      0.93      0.93       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.96      0.99      0.97       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.94      0.96      0.95       136\n",
            "          11       0.97      1.00      0.99        35\n",
            "          12       0.91      0.96      0.93       112\n",
            "          13       0.96      0.98      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.84      0.75      0.79        36\n",
            "          16       0.94      0.92      0.93        51\n",
            "          17       0.90      0.95      0.92       206\n",
            "          18       0.98      0.95      0.97        59\n",
            "          19       0.78      0.72      0.75        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.90      0.83      0.86      1926\n",
            "          22       0.94      0.97      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.97      0.97      0.97       270\n",
            "          25       0.94      0.98      0.96       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.97      0.99      0.98       697\n",
            "          28       0.99      0.98      0.99       695\n",
            "          29       0.90      0.95      0.93       146\n",
            "          30       0.94      0.91      0.92        85\n",
            "          31       0.93      0.91      0.92       331\n",
            "          32       0.98      0.89      0.93        54\n",
            "          33       0.93      0.93      0.93      1196\n",
            "          34       0.91      0.99      0.95        73\n",
            "          35       0.85      0.97      0.91       148\n",
            "          36       0.96      0.99      0.98       238\n",
            "          37       0.97      0.99      0.98       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.93      0.93      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.93      0.95      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.95       254\n",
            "          45       1.00      0.86      0.93        37\n",
            "          46       0.89      0.91      0.90        80\n",
            "          47       0.92      0.84      0.88       116\n",
            "          48       0.94      0.97      0.95       379\n",
            "          49       0.89      0.97      0.93       159\n",
            "          50       0.97      0.98      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 12_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9619552791622845\n",
            "Precision: 0.9620096349063282\n",
            "Recall: 0.9619552791622845\n",
            "F1-score: 0.9617905344060977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.64      0.72        59\n",
            "           1       0.97      0.99      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       1.00      0.98      0.99        48\n",
            "           4       0.96      1.00      0.98       132\n",
            "           5       0.89      0.94      0.91       176\n",
            "           6       0.99      0.99      0.99      1069\n",
            "           7       0.97      0.95      0.96       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      0.99      0.99       642\n",
            "          10       0.95      0.93      0.94       136\n",
            "          11       1.00      1.00      1.00        35\n",
            "          12       0.85      0.97      0.91       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       1.00      0.69      0.82        36\n",
            "          16       0.94      0.92      0.93        51\n",
            "          17       0.90      0.95      0.92       206\n",
            "          18       0.98      0.97      0.97        59\n",
            "          19       0.78      0.67      0.72        43\n",
            "          20       0.97      0.94      0.95        33\n",
            "          21       0.88      0.87      0.87      1926\n",
            "          22       0.97      0.96      0.96       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.97      0.98      0.97       270\n",
            "          25       0.98      0.96      0.97       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.97      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.91      0.94      0.92       146\n",
            "          30       0.94      0.91      0.92        85\n",
            "          31       0.93      0.92      0.92       331\n",
            "          32       0.98      0.93      0.95        54\n",
            "          33       0.95      0.92      0.94      1196\n",
            "          34       0.93      0.96      0.95        73\n",
            "          35       0.90      0.95      0.92       148\n",
            "          36       0.97      0.98      0.97       238\n",
            "          37       0.97      0.97      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      0.99      0.99       327\n",
            "          40       0.92      0.94      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.92      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.94      0.95       254\n",
            "          45       0.89      0.89      0.89        37\n",
            "          46       0.87      0.97      0.92        80\n",
            "          47       0.93      0.84      0.88       116\n",
            "          48       0.92      0.96      0.94       379\n",
            "          49       0.93      0.91      0.92       159\n",
            "          50       0.99      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.95      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 13_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9602176597009465\n",
            "Precision: 0.960140390226626\n",
            "Recall: 0.9602176597009465\n",
            "F1-score: 0.9599382997374301\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.61      0.70        59\n",
            "           1       0.97      0.98      0.98      1879\n",
            "           2       0.97      0.99      0.98       345\n",
            "           3       0.96      1.00      0.98        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.92      0.90      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.96      0.93      0.94       148\n",
            "           8       0.97      0.98      0.97       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.92      0.97      0.95       136\n",
            "          11       0.91      0.91      0.91        35\n",
            "          12       0.84      0.94      0.89       112\n",
            "          13       0.97      0.98      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.87      0.75      0.81        36\n",
            "          16       0.96      0.92      0.94        51\n",
            "          17       0.93      0.97      0.95       206\n",
            "          18       0.90      0.93      0.92        59\n",
            "          19       0.79      0.70      0.74        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.89      0.85      0.87      1926\n",
            "          22       0.96      0.97      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.98      0.96      0.97       270\n",
            "          25       0.99      0.94      0.96       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.93      0.94      0.93       146\n",
            "          30       0.94      0.89      0.92        85\n",
            "          31       0.89      0.93      0.91       331\n",
            "          32       0.96      0.87      0.91        54\n",
            "          33       0.94      0.93      0.94      1196\n",
            "          34       0.93      0.97      0.95        73\n",
            "          35       0.86      0.95      0.90       148\n",
            "          36       0.95      0.98      0.96       238\n",
            "          37       0.96      0.98      0.97       146\n",
            "          38       0.97      1.00      0.98       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.92      0.96      0.94       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.91      0.96      0.93       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.95      0.94      0.94       254\n",
            "          45       0.97      0.84      0.90        37\n",
            "          46       0.83      0.93      0.88        80\n",
            "          47       0.93      0.81      0.87       116\n",
            "          48       0.94      0.93      0.94       379\n",
            "          49       0.89      0.97      0.92       159\n",
            "          50       0.99      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 14_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9599890255612968\n",
            "Precision: 0.959843976083291\n",
            "Recall: 0.9599890255612968\n",
            "F1-score: 0.9597516602686086\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.64      0.70        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.97      0.99      0.98       345\n",
            "           3       0.98      0.98      0.98        48\n",
            "           4       0.97      0.99      0.98       132\n",
            "           5       0.91      0.91      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.96      0.95      0.95       148\n",
            "           8       0.98      0.97      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.94      0.98      0.96       136\n",
            "          11       0.81      0.97      0.88        35\n",
            "          12       0.91      0.94      0.92       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.93      0.78      0.85        36\n",
            "          16       0.96      0.92      0.94        51\n",
            "          17       0.92      0.96      0.94       206\n",
            "          18       0.98      0.92      0.95        59\n",
            "          19       0.85      0.67      0.75        43\n",
            "          20       0.94      0.94      0.94        33\n",
            "          21       0.88      0.85      0.87      1926\n",
            "          22       0.95      0.96      0.95       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.97      0.98       270\n",
            "          25       0.95      0.96      0.96       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.90      0.95      0.92       146\n",
            "          30       0.94      0.89      0.92        85\n",
            "          31       0.91      0.91      0.91       331\n",
            "          32       0.98      0.89      0.93        54\n",
            "          33       0.94      0.93      0.94      1196\n",
            "          34       0.95      0.95      0.95        73\n",
            "          35       0.90      0.95      0.93       148\n",
            "          36       0.94      0.98      0.96       238\n",
            "          37       0.96      0.97      0.96       146\n",
            "          38       0.98      1.00      0.99       142\n",
            "          39       0.98      0.99      0.99       327\n",
            "          40       0.92      0.94      0.93       203\n",
            "          41       0.98      0.99      0.98       522\n",
            "          42       0.93      0.96      0.95       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.94      0.94      0.94       254\n",
            "          45       0.94      0.78      0.85        37\n",
            "          46       0.86      0.94      0.90        80\n",
            "          47       0.91      0.82      0.86       116\n",
            "          48       0.93      0.94      0.93       379\n",
            "          49       0.90      0.94      0.92       159\n",
            "          50       0.97      0.99      0.98       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 15_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9604005670126663\n",
            "Precision: 0.9601072712558862\n",
            "Recall: 0.9604005670126663\n",
            "F1-score: 0.9599749214250375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.58      0.68        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.97      0.97      0.97       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.91      0.94      0.92       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.97      0.99      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.96      0.95      0.95       136\n",
            "          11       0.88      1.00      0.93        35\n",
            "          12       0.92      0.95      0.93       112\n",
            "          13       0.97      0.96      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.90      0.78      0.84        36\n",
            "          16       0.94      0.92      0.93        51\n",
            "          17       0.93      0.95      0.94       206\n",
            "          18       0.98      0.95      0.97        59\n",
            "          19       0.76      0.67      0.72        43\n",
            "          20       0.97      0.94      0.95        33\n",
            "          21       0.89      0.84      0.86      1926\n",
            "          22       0.96      0.96      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.96      0.97      0.97       270\n",
            "          25       0.97      0.96      0.97       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.97      0.99      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.93      0.95      0.94       146\n",
            "          30       0.97      0.88      0.93        85\n",
            "          31       0.92      0.91      0.91       331\n",
            "          32       0.98      0.98      0.98        54\n",
            "          33       0.91      0.95      0.93      1196\n",
            "          34       0.91      0.97      0.94        73\n",
            "          35       0.91      0.95      0.93       148\n",
            "          36       0.95      0.98      0.97       238\n",
            "          37       0.99      0.97      0.98       146\n",
            "          38       0.98      1.00      0.99       142\n",
            "          39       0.98      0.99      0.99       327\n",
            "          40       0.91      0.95      0.93       203\n",
            "          41       0.98      0.99      0.98       522\n",
            "          42       0.93      0.96      0.94       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.94      0.94      0.94       254\n",
            "          45       0.97      0.84      0.90        37\n",
            "          46       0.87      0.95      0.91        80\n",
            "          47       0.90      0.86      0.88       116\n",
            "          48       0.94      0.94      0.94       379\n",
            "          49       0.88      0.96      0.92       159\n",
            "          50       0.98      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.95      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 16_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.960674927980246\n",
            "Precision: 0.9604375126596268\n",
            "Recall: 0.960674927980246\n",
            "F1-score: 0.9603299474091898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.59      0.67        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.97      0.99      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.96      1.00      0.98       132\n",
            "           5       0.92      0.92      0.92       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.96      0.95      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.92      0.96      0.94       136\n",
            "          11       0.87      0.94      0.90        35\n",
            "          12       0.87      0.96      0.91       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.94      0.81      0.87        36\n",
            "          16       0.92      0.92      0.92        51\n",
            "          17       0.92      0.96      0.94       206\n",
            "          18       0.95      0.97      0.96        59\n",
            "          19       0.82      0.74      0.78        43\n",
            "          20       0.89      0.94      0.91        33\n",
            "          21       0.90      0.84      0.87      1926\n",
            "          22       0.94      0.95      0.95       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.96      0.97      0.96       270\n",
            "          25       0.96      0.97      0.97       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.91      0.95      0.93       146\n",
            "          30       0.95      0.89      0.92        85\n",
            "          31       0.94      0.92      0.93       331\n",
            "          32       0.93      0.93      0.93        54\n",
            "          33       0.93      0.94      0.94      1196\n",
            "          34       0.92      0.99      0.95        73\n",
            "          35       0.89      0.95      0.92       148\n",
            "          36       0.96      0.99      0.97       238\n",
            "          37       0.95      0.98      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      0.99      0.99       327\n",
            "          40       0.91      0.95      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.94      0.94      0.94       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.95       254\n",
            "          45       0.94      0.81      0.87        37\n",
            "          46       0.83      0.95      0.88        80\n",
            "          47       0.86      0.84      0.85       116\n",
            "          48       0.94      0.95      0.95       379\n",
            "          49       0.90      0.93      0.91       159\n",
            "          50       0.98      0.99      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 17_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.958937308518908\n",
            "Precision: 0.9591120558821215\n",
            "Recall: 0.958937308518908\n",
            "F1-score: 0.9587803865624416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.68      0.73        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.95      0.99      0.97       345\n",
            "           3       0.96      1.00      0.98        48\n",
            "           4       0.95      1.00      0.97       132\n",
            "           5       0.94      0.88      0.91       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.97      0.94      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      0.99      0.99       642\n",
            "          10       0.91      0.95      0.93       136\n",
            "          11       0.92      0.97      0.94        35\n",
            "          12       0.88      0.96      0.91       112\n",
            "          13       0.97      0.98      0.97       842\n",
            "          14       0.98      0.98      0.98      1555\n",
            "          15       0.86      0.83      0.85        36\n",
            "          16       0.98      0.90      0.94        51\n",
            "          17       0.89      0.99      0.94       206\n",
            "          18       0.95      0.95      0.95        59\n",
            "          19       0.86      0.70      0.77        43\n",
            "          20       0.97      0.94      0.95        33\n",
            "          21       0.87      0.86      0.86      1926\n",
            "          22       0.93      0.96      0.95       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.98      0.98       270\n",
            "          25       0.96      0.97      0.97       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.89      0.95      0.92       146\n",
            "          30       0.92      0.89      0.90        85\n",
            "          31       0.91      0.92      0.91       331\n",
            "          32       0.98      0.91      0.94        54\n",
            "          33       0.96      0.89      0.92      1196\n",
            "          34       0.92      0.99      0.95        73\n",
            "          35       0.90      0.95      0.92       148\n",
            "          36       0.97      0.97      0.97       238\n",
            "          37       0.98      0.95      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.93      0.96      0.94       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.93      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.93      0.94      0.93       254\n",
            "          45       0.89      0.86      0.88        37\n",
            "          46       0.81      0.96      0.88        80\n",
            "          47       0.92      0.84      0.88       116\n",
            "          48       0.93      0.96      0.94       379\n",
            "          49       0.89      0.95      0.92       159\n",
            "          50       0.97      0.99      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 18_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9607206548081759\n",
            "Precision: 0.9605350309664215\n",
            "Recall: 0.9607206548081759\n",
            "F1-score: 0.9604551088802001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.68      0.73        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.99      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.96      0.99      0.97       132\n",
            "           5       0.92      0.95      0.93       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.95      0.95      0.95       148\n",
            "           8       0.98      0.97      0.97       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.94      0.96      0.95       136\n",
            "          11       0.92      0.94      0.93        35\n",
            "          12       0.88      0.96      0.91       112\n",
            "          13       0.96      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.94      0.81      0.87        36\n",
            "          16       0.94      0.92      0.93        51\n",
            "          17       0.92      0.95      0.94       206\n",
            "          18       0.93      0.93      0.93        59\n",
            "          19       0.86      0.70      0.77        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.89      0.85      0.87      1926\n",
            "          22       0.96      0.95      0.96       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.98      0.96      0.97       270\n",
            "          25       0.96      0.95      0.96       196\n",
            "          26       0.98      0.96      0.97       450\n",
            "          27       0.97      0.99      0.98       697\n",
            "          28       0.99      0.98      0.99       695\n",
            "          29       0.91      0.92      0.92       146\n",
            "          30       0.95      0.91      0.93        85\n",
            "          31       0.90      0.92      0.91       331\n",
            "          32       0.96      0.94      0.95        54\n",
            "          33       0.95      0.93      0.94      1196\n",
            "          34       0.96      0.97      0.97        73\n",
            "          35       0.88      0.97      0.92       148\n",
            "          36       0.95      0.99      0.97       238\n",
            "          37       0.97      0.96      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.92      0.96      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.92      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.94      0.95       254\n",
            "          45       0.94      0.81      0.87        37\n",
            "          46       0.85      0.94      0.89        80\n",
            "          47       0.89      0.80      0.85       116\n",
            "          48       0.93      0.94      0.94       379\n",
            "          49       0.92      0.96      0.94       159\n",
            "          50       0.94      0.99      0.96       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 19_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.960674927980246\n",
            "Precision: 0.9603639580051713\n",
            "Recall: 0.960674927980246\n",
            "F1-score: 0.9602936591404072\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.59      0.68        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      0.98      0.98        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.93      0.91      0.92       176\n",
            "           6       0.98      0.99      0.98      1069\n",
            "           7       0.95      0.94      0.94       148\n",
            "           8       0.96      0.99      0.97       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.92      0.97      0.94       136\n",
            "          11       0.97      0.94      0.96        35\n",
            "          12       0.89      0.95      0.92       112\n",
            "          13       0.96      0.98      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.90      0.78      0.84        36\n",
            "          16       0.96      0.94      0.95        51\n",
            "          17       0.91      0.96      0.94       206\n",
            "          18       0.95      0.97      0.96        59\n",
            "          19       0.78      0.65      0.71        43\n",
            "          20       0.92      1.00      0.96        33\n",
            "          21       0.89      0.84      0.87      1926\n",
            "          22       0.93      0.96      0.95       281\n",
            "          23       1.00      1.00      1.00       634\n",
            "          24       0.97      0.96      0.97       270\n",
            "          25       0.95      0.97      0.96       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.92      0.96      0.94       146\n",
            "          30       0.91      0.91      0.91        85\n",
            "          31       0.92      0.92      0.92       331\n",
            "          32       0.98      0.96      0.97        54\n",
            "          33       0.93      0.94      0.94      1196\n",
            "          34       0.96      0.99      0.97        73\n",
            "          35       0.92      0.94      0.93       148\n",
            "          36       0.97      0.99      0.98       238\n",
            "          37       0.95      0.98      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.92      0.95      0.93       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.93      0.94      0.93       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.95       254\n",
            "          45       0.91      0.81      0.86        37\n",
            "          46       0.88      0.96      0.92        80\n",
            "          47       0.93      0.81      0.87       116\n",
            "          48       0.92      0.95      0.94       379\n",
            "          49       0.92      0.91      0.92       159\n",
            "          50       0.95      0.99      0.97       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 20_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9611321962595455\n",
            "Precision: 0.9611390311015561\n",
            "Recall: 0.9611321962595455\n",
            "F1-score: 0.9609093128172174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.66      0.74        59\n",
            "           1       0.97      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       1.00      0.98      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.91      0.93      0.92       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.94      0.96       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.95      0.94      0.94       136\n",
            "          11       0.83      0.97      0.89        35\n",
            "          12       0.89      0.95      0.92       112\n",
            "          13       0.98      0.97      0.97       842\n",
            "          14       0.98      0.98      0.98      1555\n",
            "          15       0.93      0.78      0.85        36\n",
            "          16       0.96      0.90      0.93        51\n",
            "          17       0.94      0.95      0.94       206\n",
            "          18       0.95      0.97      0.96        59\n",
            "          19       0.69      0.72      0.70        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.89      0.85      0.87      1926\n",
            "          22       0.94      0.96      0.95       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.96      0.98      0.97       270\n",
            "          25       0.97      0.95      0.96       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.97      0.99      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.92      0.94      0.93       146\n",
            "          30       0.93      0.92      0.92        85\n",
            "          31       0.91      0.94      0.92       331\n",
            "          32       0.92      0.91      0.92        54\n",
            "          33       0.96      0.92      0.94      1196\n",
            "          34       0.97      0.96      0.97        73\n",
            "          35       0.88      0.94      0.91       148\n",
            "          36       0.98      0.99      0.98       238\n",
            "          37       0.97      0.97      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.89      0.97      0.93       203\n",
            "          41       0.98      0.99      0.99       522\n",
            "          42       0.91      0.96      0.93       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.96      0.95       254\n",
            "          45       0.87      0.73      0.79        37\n",
            "          46       0.83      0.97      0.90        80\n",
            "          47       0.89      0.85      0.87       116\n",
            "          48       0.94      0.94      0.94       379\n",
            "          49       0.88      0.94      0.91       159\n",
            "          50       0.93      1.00      0.96       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 21_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9610407426036855\n",
            "Precision: 0.9608739577382499\n",
            "Recall: 0.9610407426036855\n",
            "F1-score: 0.960714469516876\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.59      0.67        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.94      0.99      0.97       132\n",
            "           5       0.91      0.94      0.92       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.96      0.96      0.96       148\n",
            "           8       0.96      0.98      0.97       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.94      0.95      0.95       136\n",
            "          11       0.92      0.94      0.93        35\n",
            "          12       0.91      0.96      0.93       112\n",
            "          13       0.98      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.90      0.78      0.84        36\n",
            "          16       0.96      0.96      0.96        51\n",
            "          17       0.92      0.96      0.94       206\n",
            "          18       0.92      0.97      0.94        59\n",
            "          19       0.83      0.79      0.81        43\n",
            "          20       0.91      0.94      0.93        33\n",
            "          21       0.90      0.85      0.87      1926\n",
            "          22       0.95      0.95      0.95       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.97      0.98      0.97       270\n",
            "          25       0.96      0.96      0.96       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.97      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.89      0.95      0.92       146\n",
            "          30       0.93      0.92      0.92        85\n",
            "          31       0.93      0.92      0.92       331\n",
            "          32       0.96      0.94      0.95        54\n",
            "          33       0.94      0.94      0.94      1196\n",
            "          34       0.92      0.96      0.94        73\n",
            "          35       0.91      0.96      0.93       148\n",
            "          36       0.98      0.99      0.98       238\n",
            "          37       0.93      0.97      0.95       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      0.99      0.99       327\n",
            "          40       0.91      0.96      0.94       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.92      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.96      0.95       254\n",
            "          45       0.93      0.76      0.84        37\n",
            "          46       0.83      0.97      0.90        80\n",
            "          47       0.95      0.83      0.88       116\n",
            "          48       0.94      0.94      0.94       379\n",
            "          49       0.87      0.94      0.91       159\n",
            "          50       0.94      0.99      0.96       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 22_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9604462938405963\n",
            "Precision: 0.9604184802960009\n",
            "Recall: 0.9604462938405963\n",
            "F1-score: 0.9601999078414066\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      0.98      0.98        48\n",
            "           4       0.95      1.00      0.97       132\n",
            "           5       0.91      0.91      0.91       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.92      0.94       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.93      0.94      0.94       136\n",
            "          11       1.00      0.91      0.96        35\n",
            "          12       0.88      0.97      0.92       112\n",
            "          13       0.97      0.98      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.93      0.69      0.79        36\n",
            "          16       0.94      0.88      0.91        51\n",
            "          17       0.90      0.97      0.93       206\n",
            "          18       0.95      0.92      0.93        59\n",
            "          19       0.86      0.70      0.77        43\n",
            "          20       0.92      1.00      0.96        33\n",
            "          21       0.88      0.85      0.87      1926\n",
            "          22       0.95      0.96      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.97      0.97      0.97       270\n",
            "          25       0.97      0.95      0.96       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.93      0.95      0.94       146\n",
            "          30       0.96      0.87      0.91        85\n",
            "          31       0.93      0.92      0.92       331\n",
            "          32       0.96      0.93      0.94        54\n",
            "          33       0.94      0.94      0.94      1196\n",
            "          34       0.97      0.97      0.97        73\n",
            "          35       0.87      0.97      0.92       148\n",
            "          36       0.97      0.98      0.98       238\n",
            "          37       0.97      0.97      0.97       146\n",
            "          38       0.98      1.00      0.99       142\n",
            "          39       0.97      1.00      0.98       327\n",
            "          40       0.89      0.95      0.92       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.95      0.89      0.92       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.96       254\n",
            "          45       0.96      0.73      0.83        37\n",
            "          46       0.83      0.97      0.90        80\n",
            "          47       0.92      0.85      0.88       116\n",
            "          48       0.93      0.94      0.94       379\n",
            "          49       0.90      0.94      0.92       159\n",
            "          50       0.96      0.99      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 23_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9609035621198957\n",
            "Precision: 0.9606653583895133\n",
            "Recall: 0.9609035621198957\n",
            "F1-score: 0.960604738434924\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.53      0.61        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.92      0.94      0.93       176\n",
            "           6       0.97      0.99      0.98      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.91      0.93      0.92       136\n",
            "          11       0.97      0.94      0.96        35\n",
            "          12       0.91      0.95      0.93       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.84      0.75      0.79        36\n",
            "          16       0.96      0.94      0.95        51\n",
            "          17       0.93      0.97      0.95       206\n",
            "          18       0.93      0.95      0.94        59\n",
            "          19       0.78      0.74      0.76        43\n",
            "          20       0.91      0.97      0.94        33\n",
            "          21       0.88      0.86      0.87      1926\n",
            "          22       0.96      0.95      0.96       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.99      0.96      0.97       270\n",
            "          25       0.97      0.94      0.96       196\n",
            "          26       0.99      0.95      0.97       450\n",
            "          27       0.98      0.99      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.92      0.96      0.94       146\n",
            "          30       0.91      0.91      0.91        85\n",
            "          31       0.91      0.91      0.91       331\n",
            "          32       0.98      0.94      0.96        54\n",
            "          33       0.94      0.94      0.94      1196\n",
            "          34       0.90      0.97      0.93        73\n",
            "          35       0.91      0.97      0.94       148\n",
            "          36       0.96      0.99      0.98       238\n",
            "          37       0.96      0.98      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.92      0.93      0.92       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.94      0.96      0.95       157\n",
            "          43       1.00      0.99      0.99      1352\n",
            "          44       0.95      0.96      0.95       254\n",
            "          45       0.94      0.81      0.87        37\n",
            "          46       0.84      0.95      0.89        80\n",
            "          47       0.94      0.82      0.88       116\n",
            "          48       0.93      0.94      0.94       379\n",
            "          49       0.90      0.94      0.92       159\n",
            "          50       0.98      1.00      0.99       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 24_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9602176597009465\n",
            "Precision: 0.9603259036015006\n",
            "Recall: 0.9602176597009465\n",
            "F1-score: 0.9598657925093917\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.66      0.70        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.96      1.00      0.98       132\n",
            "           5       0.92      0.95      0.94       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.95      0.95      0.95       148\n",
            "           8       0.96      0.98      0.97       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.93      0.95      0.94       136\n",
            "          11       0.92      0.94      0.93        35\n",
            "          12       0.84      0.96      0.90       112\n",
            "          13       0.97      0.97      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.90      0.75      0.82        36\n",
            "          16       0.96      0.96      0.96        51\n",
            "          17       0.90      0.97      0.94       206\n",
            "          18       0.92      0.97      0.94        59\n",
            "          19       0.77      0.79      0.78        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.91      0.82      0.87      1926\n",
            "          22       0.95      0.95      0.95       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.97      0.97      0.97       270\n",
            "          25       0.96      0.98      0.97       196\n",
            "          26       0.97      0.96      0.96       450\n",
            "          27       0.98      0.99      0.98       697\n",
            "          28       0.99      0.98      0.99       695\n",
            "          29       0.88      0.95      0.91       146\n",
            "          30       0.88      0.89      0.89        85\n",
            "          31       0.91      0.95      0.93       331\n",
            "          32       0.98      0.91      0.94        54\n",
            "          33       0.94      0.94      0.94      1196\n",
            "          34       0.89      0.99      0.94        73\n",
            "          35       0.88      0.97      0.92       148\n",
            "          36       0.96      0.99      0.97       238\n",
            "          37       0.95      0.97      0.96       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.97      1.00      0.98       327\n",
            "          40       0.90      0.95      0.92       203\n",
            "          41       0.98      0.99      0.98       522\n",
            "          42       0.93      0.95      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.95      0.95       254\n",
            "          45       0.91      0.81      0.86        37\n",
            "          46       0.79      0.96      0.87        80\n",
            "          47       0.92      0.84      0.88       116\n",
            "          48       0.93      0.95      0.94       379\n",
            "          49       0.84      0.96      0.90       159\n",
            "          50       0.97      0.99      0.98       106\n",
            "          51       0.99      0.99      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.93      0.95      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 25_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9617723718505647\n",
            "Precision: 0.9616950190448025\n",
            "Recall: 0.9617723718505647\n",
            "F1-score: 0.9615530584859653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.59      0.71        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.99      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.96      0.99      0.97       132\n",
            "           5       0.94      0.94      0.94       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.97      0.93      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.94      0.95      0.95       136\n",
            "          11       0.94      0.91      0.93        35\n",
            "          12       0.88      0.96      0.92       112\n",
            "          13       0.98      0.97      0.97       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.94      0.81      0.87        36\n",
            "          16       0.96      0.92      0.94        51\n",
            "          17       0.93      0.94      0.93       206\n",
            "          18       0.97      0.97      0.97        59\n",
            "          19       0.89      0.72      0.79        43\n",
            "          20       0.94      0.94      0.94        33\n",
            "          21       0.88      0.86      0.87      1926\n",
            "          22       0.96      0.96      0.96       281\n",
            "          23       0.99      1.00      0.99       634\n",
            "          24       0.99      0.98      0.98       270\n",
            "          25       0.96      0.97      0.97       196\n",
            "          26       0.98      0.95      0.96       450\n",
            "          27       0.98      0.99      0.98       697\n",
            "          28       0.99      0.99      0.99       695\n",
            "          29       0.91      0.94      0.93       146\n",
            "          30       0.93      0.92      0.92        85\n",
            "          31       0.91      0.93      0.92       331\n",
            "          32       0.98      0.94      0.96        54\n",
            "          33       0.93      0.94      0.93      1196\n",
            "          34       0.96      0.97      0.97        73\n",
            "          35       0.92      0.95      0.93       148\n",
            "          36       0.97      0.97      0.97       238\n",
            "          37       0.97      0.97      0.97       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.99      1.00      0.99       327\n",
            "          40       0.93      0.94      0.94       203\n",
            "          41       0.97      0.98      0.98       522\n",
            "          42       0.93      0.96      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.95      0.95      0.95       254\n",
            "          45       1.00      0.81      0.90        37\n",
            "          46       0.87      0.94      0.90        80\n",
            "          47       0.89      0.84      0.87       116\n",
            "          48       0.92      0.94      0.93       379\n",
            "          49       0.91      0.92      0.91       159\n",
            "          50       0.95      0.99      0.97       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.95      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 26_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9617723718505647\n",
            "Precision: 0.9616444640655052\n",
            "Recall: 0.9617723718505647\n",
            "F1-score: 0.9614636200538211\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.75        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.98      0.98      0.98       345\n",
            "           3       1.00      1.00      1.00        48\n",
            "           4       0.96      1.00      0.98       132\n",
            "           5       0.93      0.95      0.94       176\n",
            "           6       0.98      0.99      0.99      1069\n",
            "           7       0.96      0.94      0.95       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.98      1.00      0.99       642\n",
            "          10       0.93      0.96      0.94       136\n",
            "          11       0.92      0.97      0.94        35\n",
            "          12       0.88      0.96      0.92       112\n",
            "          13       0.97      0.98      0.98       842\n",
            "          14       0.98      0.99      0.98      1555\n",
            "          15       0.88      0.83      0.86        36\n",
            "          16       0.96      0.94      0.95        51\n",
            "          17       0.92      0.96      0.94       206\n",
            "          18       0.97      0.97      0.97        59\n",
            "          19       0.83      0.67      0.74        43\n",
            "          20       0.94      0.97      0.96        33\n",
            "          21       0.90      0.84      0.87      1926\n",
            "          22       0.95      0.96      0.96       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.98      0.97      0.97       270\n",
            "          25       0.96      0.97      0.97       196\n",
            "          26       0.97      0.95      0.96       450\n",
            "          27       0.98      0.98      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.93      0.95      0.94       146\n",
            "          30       0.92      0.92      0.92        85\n",
            "          31       0.92      0.92      0.92       331\n",
            "          32       0.98      0.93      0.95        54\n",
            "          33       0.92      0.95      0.93      1196\n",
            "          34       0.91      1.00      0.95        73\n",
            "          35       0.91      0.97      0.93       148\n",
            "          36       0.97      0.98      0.97       238\n",
            "          37       0.95      0.97      0.96       146\n",
            "          38       0.97      1.00      0.98       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.91      0.94      0.92       203\n",
            "          41       0.98      0.98      0.98       522\n",
            "          42       0.89      0.96      0.93       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.94      0.95      0.95       254\n",
            "          45       0.94      0.81      0.87        37\n",
            "          46       0.85      0.97      0.91        80\n",
            "          47       0.90      0.84      0.87       116\n",
            "          48       0.92      0.95      0.93       379\n",
            "          49       0.91      0.94      0.92       159\n",
            "          50       0.96      0.99      0.98       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.95      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result with model 27_model.pth : \n",
            "=========================================\n",
            "Accuracy: 0.9604005670126663\n",
            "Precision: 0.9603657685846897\n",
            "Recall: 0.9604005670126663\n",
            "F1-score: 0.9602362042289522\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72        59\n",
            "           1       0.98      0.98      0.98      1879\n",
            "           2       0.97      0.98      0.98       345\n",
            "           3       0.98      1.00      0.99        48\n",
            "           4       0.94      1.00      0.97       132\n",
            "           5       0.92      0.94      0.93       176\n",
            "           6       0.98      0.99      0.98      1069\n",
            "           7       0.94      0.92      0.93       148\n",
            "           8       0.97      0.98      0.98       663\n",
            "           9       0.99      1.00      0.99       642\n",
            "          10       0.94      0.96      0.95       136\n",
            "          11       0.91      0.91      0.91        35\n",
            "          12       0.85      0.95      0.90       112\n",
            "          13       0.97      0.98      0.97       842\n",
            "          14       0.97      0.99      0.98      1555\n",
            "          15       0.88      0.81      0.84        36\n",
            "          16       0.96      0.96      0.96        51\n",
            "          17       0.90      0.97      0.93       206\n",
            "          18       0.97      0.97      0.97        59\n",
            "          19       0.81      0.70      0.75        43\n",
            "          20       0.89      1.00      0.94        33\n",
            "          21       0.88      0.86      0.87      1926\n",
            "          22       0.96      0.96      0.96       281\n",
            "          23       0.99      1.00      1.00       634\n",
            "          24       0.98      0.97      0.97       270\n",
            "          25       0.96      0.96      0.96       196\n",
            "          26       0.98      0.95      0.97       450\n",
            "          27       0.98      0.99      0.98       697\n",
            "          28       1.00      0.98      0.99       695\n",
            "          29       0.90      0.95      0.92       146\n",
            "          30       0.92      0.89      0.90        85\n",
            "          31       0.92      0.91      0.91       331\n",
            "          32       0.96      0.87      0.91        54\n",
            "          33       0.95      0.91      0.93      1196\n",
            "          34       0.96      0.97      0.97        73\n",
            "          35       0.90      0.95      0.93       148\n",
            "          36       0.97      0.99      0.98       238\n",
            "          37       0.95      0.98      0.96       146\n",
            "          38       0.97      1.00      0.99       142\n",
            "          39       0.98      1.00      0.99       327\n",
            "          40       0.93      0.93      0.93       203\n",
            "          41       0.98      0.97      0.98       522\n",
            "          42       0.93      0.94      0.94       157\n",
            "          43       0.99      0.99      0.99      1352\n",
            "          44       0.96      0.95      0.96       254\n",
            "          45       0.94      0.84      0.89        37\n",
            "          46       0.85      0.96      0.90        80\n",
            "          47       0.93      0.85      0.89       116\n",
            "          48       0.92      0.94      0.93       379\n",
            "          49       0.92      0.90      0.91       159\n",
            "          50       0.97      1.00      0.99       106\n",
            "          51       0.99      0.98      0.99      2200\n",
            "\n",
            "    accuracy                           0.96     21869\n",
            "   macro avg       0.94      0.94      0.94     21869\n",
            "weighted avg       0.96      0.96      0.96     21869\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(actual_labels, predicted_classes)\n",
        "precision = precision_score(actual_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_classes, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "SiJYzy3heKgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_labels, predicted_classes))"
      ],
      "metadata": {
        "id": "1PEdbnvj0vPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "values = [accuracy, precision, recall, f1]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "bars = ax.bar(x, values)\n",
        "\n",
        "# labels, title, and legend\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Model Performance Metrics')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "# scores on top of each bar\n",
        "for i, bar in enumerate(bars):\n",
        "    score = values[i]\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{score:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xSO-PViWdHwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(actual_labels, predicted_classes)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "6UgUV1DcD_J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each label in predicted and true labels\n",
        "predicted_counts = np.bincount(predicted_classes)\n",
        "true_counts = np.bincount(actual_labels)\n",
        "\n",
        "# Get the unique labels\n",
        "labels = np.unique(np.concatenate((predicted_classes, actual_labels)))\n",
        "\n",
        "# Set the x-axis range\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Set the width of the bars\n",
        "width = 0.35\n",
        "\n",
        "# Plot the predicted and true label counts\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ax.bar(x - width/2, predicted_counts, width, label='Predicted Labels')\n",
        "ax.bar(x + width/2, true_counts, width, label='True Labels')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_xlabel('Labels')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Distribution of Predicted and True Labels')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "55bbdFyXajU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLUhPIJuD43X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}